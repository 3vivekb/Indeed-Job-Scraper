{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed Job Scraper and Dataizer\n",
    "By Vivek\n",
    "3/22/16\n",
    "\n",
    "Code to scrape indeed for their data on job searches.  What will it become?\n",
    "\n",
    "My plan is first to score and rank jobs.  Then maybe a framework for organizing what jobs match me by skillset.  Or finding unique words that describe jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import collocations\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://docs.python-requests.org/en/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r = requests.get('http://api.indeed.com/ads/apisearch?publisher=8538934413867228&q=data+scientist&l=san+jose%2C+ca&sort=&radius=10&st=&jt=&start=37&limit=25&fromage=&filter=&latlong=1&co=us&chnl=&userip=1.2.3.4&useragent=Mozilla/%2F4.0%28Firefox%29&v=2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTextForUrl(job_url):\n",
    "    r = requests.get(job_url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    text=soup.find(id=\"job_summary\").get_text().replace('\\n',' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_string(q,l,radius,start,age):\n",
    "    st=''\n",
    "    jt=''\n",
    "    limit=25\n",
    "    search='http://api.indeed.com/ads/apisearch?publisher=8538934413867228&q=%s&l=%s&sort=&radius=%d&st=%s&jt=%s&start=%d&limit=%d&fromage=%d&filter=1&latlong=1&co=us&chnl=&userip=1.2.3.4&useragent=Chromazord&v=2' % (q,l,radius,st,jt,start,limit,age)\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "origin = []\n",
    "maxdist = []\n",
    "url = []\n",
    "jobtitle = []\n",
    "company = []\n",
    "city = []\n",
    "state = []\n",
    "country = []\n",
    "source = []\n",
    "date = []\n",
    "snippet = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "jobkey = []\n",
    "sponsored = []\n",
    "expired = []\n",
    "snippet = []\n",
    "indeedApply = []\n",
    "#Derived\n",
    "description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q='data+scientist'\n",
    "l='san+jose%2C+ca'\n",
    "radius=20\n",
    "start=0\n",
    "age=25\n",
    "search = search_string(q,l,radius,start,age)\n",
    "req=requests.get(search)\n",
    "root = ET.fromstring(req.text)\n",
    "total_results = int(root.find('totalresults').text)\n",
    "#results = root.find('results').findall('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q='data+scientist'\n",
    "l='san+jose%2C+ca'\n",
    "radius=20\n",
    "start=0\n",
    "age=25\n",
    "for start in range(0, total_results,25):\n",
    "    search = search_string(q,l,radius,start,age)\n",
    "    req=requests.get(search)\n",
    "    root = ET.fromstring(req.text)\n",
    "    results = root.find('results').findall('result')\n",
    "    for r in results:\n",
    "        origin.append(l)\n",
    "        maxdist.append(radius)\n",
    "        url.append(r.find('url').text)\n",
    "        company.append(r.find('company').text)\n",
    "        city.append(r.find('city').text)\n",
    "        state.append(r.find('state').text)\n",
    "        jobtitle.append(r.find('jobtitle').text)\n",
    "        country.append(r.find('country').text)\n",
    "        source.append(r.find('source').text)\n",
    "        date.append(r.find('date').text)\n",
    "        jobkey.append(r.find('jobkey').text)\n",
    "        snippet.append(r.find('snippet').text)\n",
    "        latitude.append(r.find('latitude').text)\n",
    "        longitude.append(r.find('longitude').text)\n",
    "        sponsored.append(r.find('sponsored').text)\n",
    "        expired.append(r.find('expired').text)\n",
    "        indeedApply.append(r.find('indeedApply').text)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "for each in url:\n",
    "    description.append(getTextForUrl(each))\n",
    "    print(counter)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(description)\n",
    "len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
    "df = pd.DataFrame({'jobtitle' : jobtitle, \"company\" : company, 'city' : city, \"state\" : state, \n",
    "                   \"country\" : country, \"source\" : source, \"date\" : date, \n",
    "                   \"jobkey\" : jobkey, \"description\" : description, \"snippet\" : snippet,\n",
    "                   \"latitude\" : latitude, \"longitude\" : longitude, \"sponsored\" : sponsored,\n",
    "                   \"expired\" : expired, \"indeedApply\" : indeedApply, 'origin' : origin})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu, 07 Apr 2016 00:06:54 GMT'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 1\n",
    "results[num].find('date').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = datetime.date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf = today + \" sanjosejobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"sanjosejobs.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.description[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first = df.description[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Position : Data Scientist – ModellerLocation : San Jose, CADuration: Fulltime / Permanent1)Data Scie'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Position',\n",
       " ':',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " '–',\n",
       " 'ModellerLocation',\n",
       " ':',\n",
       " 'San',\n",
       " 'Jose',\n",
       " ',',\n",
       " 'CADuration',\n",
       " ':',\n",
       " 'Fulltime',\n",
       " '/',\n",
       " 'Permanent1',\n",
       " ')',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " '–*',\n",
       " '*ModellerFluent',\n",
       " 'in',\n",
       " 'Python.HADOOP',\n",
       " ',',\n",
       " 'Java',\n",
       " ',',\n",
       " 'Python',\n",
       " ',',\n",
       " 'HIVE/PIG',\n",
       " 'for',\n",
       " 'extracting',\n",
       " 'and',\n",
       " 'parsing',\n",
       " 'data.Visualization',\n",
       " 'Skills',\n",
       " '-',\n",
       " 'JavaScript',\n",
       " '(',\n",
       " 'especially',\n",
       " 'D3.js',\n",
       " ')',\n",
       " '.The',\n",
       " 'person',\n",
       " 'should',\n",
       " 'have',\n",
       " 'some',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'Stats',\n",
       " '&',\n",
       " 'Machine',\n",
       " 'Learning.Position',\n",
       " ':',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " '–',\n",
       " 'Software',\n",
       " 'Engineer',\n",
       " '(',\n",
       " 'SWE',\n",
       " ')',\n",
       " 'ModellerLocation',\n",
       " ':',\n",
       " 'San',\n",
       " 'Jose',\n",
       " ',',\n",
       " 'CADuration',\n",
       " ':',\n",
       " 'Fulltime',\n",
       " '/',\n",
       " 'Permanent2',\n",
       " ')',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " '–',\n",
       " 'Software',\n",
       " 'Engineer',\n",
       " '(',\n",
       " 'SWE',\n",
       " ')',\n",
       " 'Statistical/data',\n",
       " 'modeling/data',\n",
       " 'mining',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learningProficiency',\n",
       " 'in',\n",
       " 'SQL',\n",
       " 'and',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'petabytes',\n",
       " 'of',\n",
       " 'log',\n",
       " 'files',\n",
       " 'and',\n",
       " 'other',\n",
       " 'unstructured',\n",
       " 'data.Python/R/Java/Scala/C/C++',\n",
       " ',',\n",
       " 'Spark',\n",
       " ',',\n",
       " 'Hadoop',\n",
       " ',',\n",
       " 'Hive',\n",
       " ',',\n",
       " 'Hbase',\n",
       " ',',\n",
       " 'text/NLP',\n",
       " ',',\n",
       " 'GPUsPeople',\n",
       " 'with',\n",
       " 'Computer',\n",
       " 'Science',\n",
       " 'backgroundEducation',\n",
       " ':',\n",
       " 'MS',\n",
       " '/',\n",
       " 'PhD',\n",
       " 'in',\n",
       " 'Engineering',\n",
       " ',',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'operations',\n",
       " 'research',\n",
       " 'etcJob',\n",
       " 'Responsibilities',\n",
       " ':',\n",
       " 'Develop',\n",
       " 'predictive',\n",
       " 'models',\n",
       " 'and',\n",
       " 'provide',\n",
       " 'statistical',\n",
       " 'insights',\n",
       " 'using',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'MachineLearning.Analyze',\n",
       " 'petabytes',\n",
       " 'of',\n",
       " 'real-world',\n",
       " 'performance',\n",
       " 'data',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'trends.Transform',\n",
       " 'these',\n",
       " 'insights',\n",
       " 'into',\n",
       " 'actionable',\n",
       " 'reports',\n",
       " ',',\n",
       " 'targeting',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'and',\n",
       " 'personalizationfactors.Provide',\n",
       " 'technical',\n",
       " 'expertise',\n",
       " 'in',\n",
       " 'statistical',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'data',\n",
       " 'mining',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'NLP',\n",
       " ',',\n",
       " 'andInformation',\n",
       " 'Retrieval.Design',\n",
       " 'and',\n",
       " 'deliver',\n",
       " 'scalable',\n",
       " 'software',\n",
       " 'applications',\n",
       " 'in',\n",
       " 'Hadoop',\n",
       " 'and',\n",
       " 'in',\n",
       " 'real-time',\n",
       " 'platforms.Estimate',\n",
       " 'engineering',\n",
       " 'effort',\n",
       " ',',\n",
       " 'plan',\n",
       " 'implementations',\n",
       " ',',\n",
       " 'and',\n",
       " 'roll',\n",
       " 'out',\n",
       " 'applications',\n",
       " 'with',\n",
       " 'cross-functionalimpact.Work',\n",
       " 'jointly',\n",
       " 'with',\n",
       " 'other',\n",
       " 'team',\n",
       " 'members',\n",
       " 'to',\n",
       " 'deliver',\n",
       " 'complex',\n",
       " 'applications.Conceptualizing',\n",
       " ',',\n",
       " 'coding',\n",
       " ',',\n",
       " 'deploying',\n",
       " ',',\n",
       " 'and',\n",
       " 'iterating',\n",
       " 'on',\n",
       " 'next',\n",
       " 'generation',\n",
       " 'prototypes.Knowledge',\n",
       " ',',\n",
       " 'Skills',\n",
       " 'and',\n",
       " 'Experience',\n",
       " ':',\n",
       " 'Strong',\n",
       " 'statistical/data',\n",
       " 'modeling/data',\n",
       " 'mining',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'expertise.Excellent',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'fundamentals',\n",
       " ',',\n",
       " 'data',\n",
       " 'structures',\n",
       " ',',\n",
       " 'and',\n",
       " 'algorithms.Successful',\n",
       " 'research',\n",
       " 'track',\n",
       " 'record',\n",
       " ',',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'applied',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'orstatistical',\n",
       " 'modeling',\n",
       " '.',\n",
       " '(',\n",
       " 'optional',\n",
       " ')',\n",
       " 'Familiarity',\n",
       " 'with',\n",
       " 'predictive',\n",
       " 'models/search/recommendation/classification',\n",
       " 'applications',\n",
       " 'anddomains',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'plus.Proficiency',\n",
       " 'in',\n",
       " 'SQL',\n",
       " 'and',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'petabytes',\n",
       " 'of',\n",
       " 'log',\n",
       " 'files',\n",
       " 'and',\n",
       " 'other',\n",
       " 'unstructured',\n",
       " 'data.Experience',\n",
       " 'in',\n",
       " 'Python/R/Java/Scala.Experience',\n",
       " 'in',\n",
       " 'Hadoop',\n",
       " ',',\n",
       " 'Hive',\n",
       " ',',\n",
       " 'Hbase',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'plus.Solid',\n",
       " 'verbal',\n",
       " 'and',\n",
       " 'written',\n",
       " 'communication',\n",
       " 'skills.RegardsSyed2019-497-1010',\n",
       " 'x101Job',\n",
       " 'Type',\n",
       " ':',\n",
       " 'Full-timeSalary',\n",
       " ':',\n",
       " '$',\n",
       " '115,000.00',\n",
       " '/yearRequired',\n",
       " 'experience',\n",
       " ':',\n",
       " 'Data',\n",
       " 'Scientist',\n",
       " ':',\n",
       " '2',\n",
       " 'yearsRequired',\n",
       " 'education',\n",
       " ':',\n",
       " 'Doctorate']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_word_bag = df.description.apply(lambda t: t.lower() + \" \").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'job description  the medical sieve group in cognitive computing foundations department at ibm research - almaden is looking for candidates in biomedical and clinical informatics for a new long term research project combining clinical and imaging data for enhancing clinical decision making in radiology, cardiology and other modalities. this is a position accepting applicants with bachelors or masters in electrical engineering/computer science or related field. candidates with background in medical text analysis, data management, clinical knowledge and reasoning, medical imaging analysis and analysis of large textual collections is desirable. knowledge and experience in clinical terminologies and coding systems such as umls is also preferred. applicant may have to travel to a client site for extraction, collection and gathering of data for analysis and machine learning. applicantswill be working with research scientists assisting them in data collection,data management, annotations, medical imaging and text analysis.  the world is our laboratory no matter where discovery takes place, ibm researchers push the boundaries of science, technology and business to make the world work better. ibm research is a global community of forward-thinkers working towards a common goal: progress. qualifications  null  additional information  null position : data scientist – modellerlocation : san jose, caduration: fulltime / permanent1)data scientist –* *modellerfluent in python.hadoop, java, python , hive/pig for extracting and parsing data.visualization skills - javascript (especially d3.js).the person should have some knowledge of stats & machine learning.position : data scientist – software engineer (swe)modellerlocation : san jose, caduration: fulltime / permanent2) data scientist – software engineer (swe)statistical/data modeling/data mining and machine learningproficiency in sql and dealing with petabytes of log files and other unstructured data.python/r/java/scala/c/c++, spark, hadoop, hive, hbase, text/nlp, gpuspeople with computer science backgroundeducation : ms / phd in engineering, mathematics, computer science, statistics,operations research etcjob responsibilities: develop predictive models and provide statistical insights using big data tools and machinelearning.analyze petabytes of real-world performance data to understand patterns and trends.transform these insights into actionable reports, targeting algorithms, and personalizationfactors.provide technical expertise in statistical analysis, data mining, machine learning, nlp, andinformation retrieval.design and deliver scalable software applications in hadoop and in real-time platforms.estimate engineering effort, plan implementations, and roll out applications with cross-functionalimpact.work jointly with other team members to deliver complex applications.conceptualizing, coding, deploying, and iterating on next generation prototypes.knowledge, skills and experience: strong statistical/data modeling/data mining and machine learning expertise.excellent understanding of computer science fundamentals, data structures, and algorithms.successful research track record, focused on applied machine learning, information retrieval orstatistical modeling. (optional)familiarity with predictive models/search/recommendation/classification applications anddomains will be a plus.proficiency in sql and dealing with petabytes of log files and other unstructured data.experience in python/r/java/scala.experience in hadoop, hive, hbase will be a plus.solid verbal and written communication skills.regardssyed2019-497-1010 x101job type: full-timesalary: $115,000.00 /yearrequired experience:data scientist: 2 yearsrequired education:doctorate description intuit quickbooks is on a mission to transform small business lending through its quickbooks financing platform. powerful analytics and a sophisticated understanding of our customers is at the heart of our business. we are looking for a talented data scientist to join our team and help build financing solutions that delight our smb customers. if you are excited about joining a highly ambitious and talented startup team, then keep reading!  responsibilities: possess a wide-latitude in determining objectives and approaches to solution development on mission critical assignments  go beyond established analytical thinking and problem-solving by applying creativity to unconventional concepts and out-of-the-box solutions  quickly understand patterns within large quantity of data and to reference key characteristics using visualization techniques  collaborate with infrastructure architects in assessing and addressing the requirements for more automated, streamlined systems and for the data governance required for agile and responsive data manipulation  build and refine a predictive model around when small businesses are most likely to need financing  inform business decisions by building a comprehensive view of our customers by combining relevant data and signals from multiple sources  make recommendations to enhance marketing strategy by deeply understanding the performance of every channel  partner directly with the product development team on product instrumentation, product flow and data capture  inform product strategy by designing a/b tests and analyzing customer behavior on our platform  build dashboards to support day to day business decisions  work closely with product, marketing, legal, compliance, capital markets and our current lending partners qualifications  proven leadership experience in the domain of data science  ms in engineering mathematics, statistics, theoretical/computational physics, or related field  solid knowledge of statistical techniques is required  hands-on programming experience with one or more of the following: java, python, r, or related languages  1-3+ years’ experience manipulating large datasets and using databases (e.g. sas, r, sql, s-plus, etc.)  1-3+ years’ experience with a general-purpose programming language (e.g. c, java, python, etc.)  familiarity with basic principles of distributed computing and/or distributed databases (hadoop, nosql, etc.)  demonstrable ability to quickly understand new concepts---all the way down to the theorems—and to come out with original solutions to mathematical issues  strong interpersonal and communication skills in order to effectively contribute to technical teams and make presentations to a variety of technical and business personnel  demonstrable skills in creative-problem-solving of complex and advanced technical subject matter  strongly preferred: phd in engineering mathematics, statistics, theoretical/computational physics, or related field  proven experience with machine learning techniques, especially on large scale datasets  proven experience with hadoop and related programming environments (hive,pig,etc)  imagine a career where your creative inspiration can fuel big innovation. year-over-year, intuit has been recognized as a best employer and is consistently ranked on fortune\\'s “100 best companies to work for” and fortune world’s “most admired software companies” lists. immerse yourself in our award winning culture while creating breakthrough solutions that simplify the lives of consumers and small businesses and their customers worldwide. intuit is expanding its social, mobile, and global footprint with a full suite of products and services that are revolutionizing the industry. utilizing design for delight and lean startup methodologies, our entrepreneurial employees have brought more than 250 innovations to market -- from quickbooks®, quicken®, and turbotax®, to gopayment, mint.com, big data, cloud (saas, paas) and mobile apps. the breadth and depth of these customer-driven innovations mean limitless opportunities for you to turn your ingenious ideas into reality at intuit.discover what it’s like to be part of a team that rewards taking risks and trying new things. it’s time to love what you do! check out all of our career opportunities at: http://jobs.intuit.com . eoe aa m/f/vet/disability (menlo park, ca) careers at oculus a facebook company we’re looking for data scientists to work on our core and business products at oculus with a passion for internet technology to help drive informed business decisions for oculus. you will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into real products on a regular basis. the perfect candidate will have a background in a quantitative or technical field, will have experience working with large data sets, and will have some experience in data-driven decision making. you are scrappy, focused on results, a self-starter, and have demonstrated success in using analytics to drive the understanding, growth, and success of a product.  responsibilities apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with our core/business products partner with product and engineering teams to solve problems and identify trends and opportunities inform, influence, support, and execute our product decisions and product launches. the data scientist analytics role has work across the following four areas: data infrastructure working in hadoop and hive primarily, sometimes mysql, oracle, and vertica authoring pipelines via sql and python based etl framework building key data sets to empower operational and exploratory analysis automating analyses product operations setting goals designing and evaluating experiments monitoring key product metrics, understanding root causes of changes in metrics building and analyzing dashboards and reports exploratory analysis proposing what to build in the next roadmap understanding ecosystems, user behaviors, and long-term trends identifying levers to help move key metrics evaluating and defining metrics building models of user behaviors for analysis or to power production systems product leadership influencing product teams through presentation of work communicating of state of business, experiment results, etc to product teams spreading best practices to analytics and product teams requirements 4+ years experience doing quantitative analysis. ba/bs in computer science, math, physics, engineering, statistics or other technical field. advanced degrees preferred.  experience in sql or other programming languages. development experience in at least one scripting language (php, python, perl, etc.) ability to initiate and drive projects to completion with minimal guidance ability to communicate the results of analyses in a clear and effective manner basic understanding of statistical analysis. preferred experience with a statistical package such as r, matlab, spss, sas, stata, etc. preferred experience with an internet-based company.  experience with large data sets and distributed computing (hive/hadoop) a plus. apply as part of our dedication to the diversity of our workforce, facebook is committed to equal employment opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. if you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com or you may call us at 1+650-308-7837. data scientist with pythonlocation: cupertino carequesting a python expert to work on a text classification project in the ols area.responsibilities are as follows: 1. work closely and collaboratively with business users & gbi teams to understand the requirements 2. design and build a text classification application using different text classification models3. prior experience in using natural language processing (nlp) and text mining/ml packages (such as gensim for topic modeling, nltk, scikitlearn packages for classifier building etc.)4. familiar with writing the codes to optimize performance/speed5. reasonable knowledge of database (preferably teradata)job type: contractsalary: $60,000.00 /hourrequired experience:nltk, scikitlearn packages (nlp) and text mining/ml packages: 1 year requisition no.: 121517br  subsidiary: ebay marketplaces primary job responsibilities: do you crave technical challenges at scale and love working on a fast-paced team? like working on high profile projects seen by millions daily? the ads, merch & traffic team is seeking a talented, creative, and passionate data scientist, who will work closely with engineering teams, pm & analysts to cultivate a deep understanding of the ever-evolving systems, processes, and most importantly, data upon which our business runs. you should be experienced with and passionate about using data to drive strategy and product recommendations. the ideal candidate is an independent, solution-oriented thinker with a strong background processing huge data sets, applying analytical rigor and statistical methods, and driving toward insights and solutions  job requirements: do you crave technical challenges at scale and love working on a fast-paced team? like working on high profile projects seen by millions daily? the ads, merch & traffic team is seeking a talented, creative, and passionate data scientist who will work closely with engineering teams, pm & analysts to cultivate a deep understanding of the ever-evolving systems, processes, and most importantly, data upon which our business runs. you should be experienced with and passionate about using data to drive strategy and product recommendations. the ideal candidate is an independent, solution-oriented thinker with a strong background processing huge data sets, applying analytical rigor and statistical methods, and driving toward insights and solutions.  who are we? the ads, merch & traffic team is revolutionizing the ads & recommendations on and off ebay. our goal is to “create an engaging experience for users by serving contextual promotional content”, and we’re on our way. we are growing at a rapid pace and committed to building an all-star team. we are a team where people who take risks and win are rewarded and grow. our team is ambitious and passionate; the environment is relaxed and fun. we get things done that make a difference. last updated: 03/02/2016 requisition no.: 29374br  subsidiary: paypal  category: trust safety & fraud  shift: day  primary job responsibilities: paypal, inc. seeks data scientist in san jose, ca: collaborate with architects, engineers, data scientists and paypal risk teams to architect and develop strategic and tactical solutions using paypal´s proprietary technology as well as open source distributed computing technology such as hadoop. design, develop and test projects jointly with other team members to deliver and deploy complex applications in paypal´s production system. req’s: phd (or equiv) or ms (or equiv.) + 3 years exp. must be legally authorized to work in us w/o sponsorship. submit resume w/ ref. to: req. #: yc920(pc) to: hr, paypal, inc. hq, cube 15.1.131, 2211 north first street, san jose, ca 95131. eoe.  job requirements: .  last updated: 03-mar-2016 requisition no.: 119481br  subsidiary: ebay marketplaces primary job responsibilities: senior data scientist/applied researcher role working within the search science team at ebay. job requirements: you are well versed in areas such as applied statistics, machine learning, data mining and general algorithms. you have a background in computer science or math and a graduate degree in computer science, math, physics, computational biology, economics, or some other science. a hacker. if something you need doesn’t exist you don’t wait around, you go and build it. then you share it with others on the team and turn it into an open source project. proficient with data stores like sql and hadoop. you’re not necessarily an expert, but you’ve written some queries and done some mapreducing. inherently curious. you want to know whether the distribution of the query frequency on ebay.com is zipfian and what family of random graphs models the relationship between sellers and buyers on ebay. a polyglot programmer. you probably have a favorite language like scala or r but you can jump in and write some java or c as needed. results oriented. research is great but at the end of the day you want to see your creation live and breathe. you have a history of building things and solving real problems. you will be directly responsible for improving search at ebay via services such as spell corrections, result set ranking, related searches, synonym/acronym expansions, and query rewrites. conceptualize, code, deploy, and iterate on designs from prototypes all the way through to production systems. analyze petabytes of real-world performance data to understand patterns and trends. transform data insights into actionable reports, targeting algorithms, and model features. provide technical expertise in statistical analysis, data mining, machine learning, nlp, and information retrieval. work jointly with architects, engineers, qe, and operations to deliver complex applications. last updated: 11/04/2015 position: data scientist / big data engineer – advance analyticslocation:  san jose, caduration:  full-timejob responsibilities: develop predictive models and provide statistical insights using big data tools and machine learning.analyze petabytes of real-world performance data to understand patterns and trends.transform these insights into actionable reports, targeting algorithms, and personalization factors.provide technical expertise in statistical analysis, data mining, machine learning, nlp, and information retrieval.design and deliver scalable software applications in hadoop and in real-time platforms.estimate engineering effort, plan implementations, and roll out applications with cross-functional impact.work jointly with other team members to deliver complex applications.conceptualizing, coding, deploying, and iterating on next generation prototypes.knowledge, skills and experience: strong statistical/data modeling/data mining and machine learning expertise.excellent understanding of computer science fundamentals, data structures, and algorithms.successful research track record, focused on applied machine learning, information retrieval or statistical modeling. (optional)familiarity with predictive models/search/recommendation/classification applications and domains will be a plus.proficiency in sql and dealing with petabytes of log files and other unstructured data.experience in python/r/java/scala.experience in hadoop, hive, hbase will be a plus.solid verbal and written communication skills.education: ms / phd in engineering, mathematics, computer science, statistics, operations research etcrequired experience:r, sql, sas, python, regression, modeling: 2 years discovering the perfect course is the first and often most important step in ensuring an amazing learner experience on coursera. with over 1,500 courses to date, however, finding the perfect course for a given learner\\'s goals and interests can be highly non-trivial. we\\'re looking for a talented, independent data scientist with a sharp eye for ux design, strong algorithmic and analytic skills, and experience with large-scale machine learning systems to join the growth analytics team at coursera. in this role, you’ll be directly involved in the design, implementation, and evaluation of discovery products ranging from on-platform catalog search to course and content recommendation. your responsibilities: building content discovery products designing and interpreting the results of a/b tests around content discovery analyzing data to identify and prioritize optimization opportunities working cross-functionally with engineers and designers your skills: direct experience with building complex machine learning systems strong background in math/stats/ml/nlp proficiency with at least one programming language (e.g., python) proficiency with at least one statistical software package (e.g., r) excellent communication and project management skills  an ideal candidate will also have: 2+ years of industry experience proficiency with relational databases and sql familiarity with domain-specific technologies and challenges in search and discovery requisition id: 105756 work area: software-design and development expected travel: 0 - 20% career status: graduate employment type: regular full time  company description  as market leader in enterprise application software, sap helps companies of all sizes and industries innovate through simplification. from the back office to the boardroom, warehouse to storefront, on premise to cloud, desktop to mobile device – sap empowers people and organizations to work together more efficiently and use business insight more effectively to stay ahead of the competition. sap applications and services enable customers to operate profitably, adapt continuously, and grow sustainably.  expectations and tasks  a developer with data science background executes the mathematical modelling of our customers\\' business problems, develops algorithms and applications to solve these problems, and creates new innovation solutions to resolve our customers real problem.  willingness and ability to design in the area of prediction, optimization, and processes using advanced statistical / mathematical approaches, in the enterprise environment.  identify new and emerging patterns and improve the models through data mining. design best structure and select the most appropriate modeling techniques, which includes a variety of machine learning algorithms.  experience in hands-on software development ability to capture customer requirements and translate them into software specifications learn quickly new mathematical or technical methods  education and qualification / skills and competencies   m.s. or ph.d. in computer science, electrical engineering, statistics, applied math or related topics strong background in mathematics, statistics and programming familiar with one or more machine learning or statistical modeling tools such as r, matlab and scikit learn, torch, caffe etc. proficient in one or more programming languages such as python, javascript and c etc. knowledge and experience of working with relational databases. strong analytical and quantitative problem solving ability. excellent communication, relationship skills and a strong team player. very strong verbal and written communication skills as well as excellent presentation skills.  preferred qualifications  experience with big data techniques (such as hadoop, spark) strong industry domain knowledge and experience preferred  sap\\'s diversity commitment  to harness the power of innovation, sap invests in the development of its diverse employees. we aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.  sap is committed to the principles of equal employment opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. if you are interested in applying for employment with sap and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to recruiting operations team (americas: careers.northamerica@sap.com or careers.latinamerica@sap.com , apj: careers.apj@sap.com , emea: careers@sap.com ). requests for reasonable accommodation will be considered on a case-by-case basis.  eoe aa m/f/vet/disability: qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability. additional locations: no selection additional location(s) or information: job category: project or program management level of experience: experienced - non manager  requisition #: r1006732 description: data analyst/scientist, software quality san jose, ca  the business entity the cisco core software group is the world leader in the networking industry delivering leading innovations and changing how networking is done. we are looking for a software quality data analyst to play a leading role in big data learning and applying action plans, for software quality and others, based on conclusions from data. you will help to define and drive engineering process change and quality improvement initiatives across several product lines including switching, routing, optical, data center and wireless products.  the team the successful candidate will have a unique blend of analytical ability, business aptitude and strong interpersonal skills, with a proven background in defining and driving complex initiatives across large cross-functional teams. the ideal candidate brings a track record of success in a similar role, strong leadership skills, and a can-do attitude.  this is a challenging opportunity to influence a large engineering organization responsible for many billion dollars revenue and impacting quality of online experience worldwide. are you ready for the challenge?  role & responsibilities  use data and analytical ability to find and interpret rich data sources; manage large amounts of data; merge data sources; ensure consistency of datasets; create visualizations to aid in understanding data; build mathematical models using the data; and present and communicate the data insights/findings analyze and interpret quality data to identify improvement areas. develop sw quality improvement programs targeted at increasing software customer satisfaction provide leadership in engineering process, quality measurement, and translating metrics into a set of actionable tasks work with cross-functional stakeholder to define quality and productivity improvement projects and drive them from inception to completion act as quality, metrics and process champion internally as well as in other cisco forums involving cross-functional teams  minimum qualifications  master’s degree in computer science/engineering with 7 years of experience or bachelor\\'s degree with 10+ years of experience. 2+ years of experience in program management and 3-5 years of experience in data analytics, sw quality, and/or engineering process experience with dash boards  experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, large-scale data mining or artificial intelligence.  understanding and usage of data metrics and analysis tools such as: hadoop, tableau, platfora, ms access databases, sql ability to work well with sr management as well as technical contributors. excellent leadership, management, influencing, conflict resolution, and team building skills. strong writing and presentation skills, ability to create collateral or presentations that are clearly written and succinct, comfortable presenting to small groups, internal stakeholders, and executives. strong team work and collaboration skills, with track record of leading cross-functional teams  desired skills  six-sigma green/black belt certification. familiar with one or more standard project management techniques such as dmaic, six-sigma, agile scrum,  proficient with bigdata , shell scripting, python programming etc.  strong background and passion for analysis, data driven decision making, and out-side-the box thinking basic knowledge of networking products (preferably cisco products) and networking market segments as related to sw quality and metrics.  about cisco the internet of everything is a phenomenon driving new opportunities for cisco and it\\'s transforming our customers\\' businesses worldwide. we are pioneers and have been since the early days of connectivity. today, we are building teams that are expanding our technology solutions in the mobile, cloud, security, it, and big data spaces, including software and consulting services. as cisco delivers the network that powers the internet, we are connecting the unconnected. imagine creating unprecedented disruption. your revolutionary ideas will impact everything from retail, healthcare, and entertainment, to public and private sectors, and far beyond. collaborate with like-minded innovators in a fun and flexible culture that has earned cisco global recognition as a great place to work. with roughly 10 billion connected things in the world now and over 50 billion estimated in the future, your career has exponential possibilities at cisco.  @ciscojobs is #hiring #software quality #metrics #six sigma #damaic #project management #program management #bigdata #data scientist #analytics   li-cb1 job type: experienced opportunity category: data center, internet of everything, wireless   about retail solutions, inc.: retail solutions develops and delivers a comprehensive suite of award-winning software-as-a-service (saas) solutions that turn retailer “downstream data”, such as point-of-sale (pos), supply chain, merchandiser feedback and category data, into actionable visibility into the store and onto the shelf for their suppliers.  retail solutions, the largest and fastest-growing company in the retail execution management field, has more experience with processing customer-specific retailer data than any other company. retailers and consumer product goods (cpg) companies trust retail solutions to grow sales, reduce out-of-stocks, improve promotion execution and effectiveness, maximize retail operation productivity and foster collaborative relationships in the retail industry to improve product availability for the end-consumer.  retail solutions serves more than 500 cpg companies, including nine of the top ten global consumer goods companies, and processes data from more than 30 leading retailers in the americas and europe.  retail solutions is headquartered in mountain view, ca and has offices in cranston, ri; bentonville, ar; paris, france; richmond, uk; and shanghai, china.  position summary: the data scientist will drive and participate in the design and implementation of algorithms working with the retail and supply chain data. this needs knowledge of statistical modeling, data mining, and machine learning concepts, and includes understanding business requirements, conducting advanced data analysis, designing algorithms, providing algorithm specifications and also the corresponding tweaking/tuning guidelines.  the data scientist will be responsible for helping on the defining and performing advanced analyses against large and varying data sets related to retail sales and operations in support of various retail solutions’ customer driven solution creation. the objective of these analyses will be to answer important business questions and should result in input parameters and/or new algorithms to be leveraged in highly-sophisticated analytic applications. this individual will work closely with a team of product manager, r&d;, and software engineers to provide the solution.  rsi is growing rapidly, and the work atmosphere is team-oriented and knowledge-intensive: motivated professionals are highly appreciated.  essential duties and responsibilities: analyze the various data sets, based on the business goal, find the characteristics of the data and create proper advanced models for them.  develop and implement algorithms to solve business problems.  tweaking/tuning the model for better accuracy, performance, etc.  qualifications: master degree or higher in statistics with courses completed on the machine learning, statistics, prediction algorithms and/or related areas.  2+ years of experiences on industrial analytical areas especially big data analytics (statistical modeling, machine learning and predictive analysis).  knowledge and experiences in the supply chain area is very preferred.  having knowledge on the statistics, predictive analysis and modeling, machine learning and/or related areas, and having projected completed on those areas.  familiar with r programming, can use r to create analysis programs using linear regression, pattern recognition, machine learning methods.  having basic sql knowledge and skills, can write sql queries for retrieving the data from the data repository db.  having data visualization and representation skills.  experience developing data-driven analytical models of various operations / policies.  fluent oral and written communication skills in english.  a team-worker: willing to work with colleagues.  personal attributes  good written and oral communication skills.  strong scientific documentation skills.  good interpersonal skills.  ability to present ideas in user-friendly language.  highly self-motivated and directed.  keen attention to detail.  reporting to this position: no direct reports the bioinformatics, data analysis and statistics (bdas) group at ariosa diagnostics is seeking a motivated data scientist to join the team. come join this highly talented and multi-disciplinary team of bioinformaticians, software engineers, and statisticians, and help us develop the next generation of paradigm-shifting molecular diagnostics products that have the potential to improve the quality of healthcare worldwide. the successful incumbent will devote all of his or her professional effort to exploring various high-dimensional datasets emanating from ariosa’s customers worldwide in order to improve the quality of our existing products and to develop new content for future products. the ideal candidate will be passionate about large and complex dna datasets.  responsibilities: design data management infrastructure to clean, organize, and manage terabytes of research and development data produced by the ariosa’s internal and external customers. establishment of data management procedures for long-term data storage and access. integration of internally and externally produced unstructured, semi-structured, and relational data sources. support internal and external customers request for in-depth analyses. collaboration with other teams to identify and support various needs that are addressed by bdas data stores. interact with other functional areas to provide training, documentation and support. develop new software, analyses and reports to support both production and development operations.  requirements: we seek an individual with a successful track record who is comfortable with a fast-paced environment. the ideal candidate will have:  bachelor’s degree in computer science, computer engineering, bioinformatics, statistics, physics, or related disciplines with 10+ years of experience. master’s or ph.d. degree preferred. extensive experience working with large datasets. experience with genetic, oncology, and next-generation sequencing data is also a plus. experience developing in java preferred. also of value: c#, c++, and/or python experience using statistical software such as r, s-plus, or sas. experience developing in r is preferred. strong communication skills with the ability to maintain open communication with fellow employees, managers, and customers as needed. ability to take ownership of each project.  ability to work as part of a team. a self-starter. the role  play a central role in designing and developing major components of the next generation stream and batch processing system for tesla.  build and configure solutions that use apache kafka alongside hadoop, stream processing, relational and nosql databases and tune them for performances at scale.  implement data pipelines to automate the ingestion, transformation, and augmentation of both structured and unstructured data sources, and provide best practices for pipeline operations.  work with business analysts, application developers and data scientists to implement solutions using agile methodologies.  requirements  4+ years designing, building, and operating in-production big data, stream processing, and/or enterprise data integration solutions using apache kafka.  solid experience of building complex data pipelines.  extremely proficient in java/scala programming. knowledge of go a plus.  1+ years of hands on managing and administering storm/spark or samza, zookeeper and nosql storage.  proficiency with hdfs and mapreduce.  knowledge of rules based decision making, information parsing and complex data mining.  experience engineering large scale data infrastructures.  experience contributing to open source projects and working with open source community.  strong desire to tackle hard technical challenges and ability to work with minimum daily supervision.  strong desire to learn and implement cutting edge technology. requisition no.: 29268br  subsidiary: paypal  category: data science & analytics  shift: varies  primary job responsibilities: global analytics is a centralized team in paypal’s operations organization. the team is comprised of business analysts, strategy consultants, data scientists, modelers, and statisticians; and is uniquely focused on developing models that feeds in to cross channel customer experience engine that enables customized offers, messaging and action that improves engagement and life time value of a consumer or merchant affecting the paypal’s 173mm total active customer accounts.  job requirements: the data science in global analytics team focuses on applicative research, analysis and development of innovative components to grow engagement and life time value of consumer & merchant, specifically in the areas of predictive behavior analytics. our focus is the analysis of the massive paypal data, across sales, marketing, product and overall business analytics functional areas with modeling software to crunch it and deliver human-readable insights for business decisions.  last updated: 01-mar-2016 as a leading fortune 500 technology & security company, symantec already protects more than a billion iot devices, putting symantec among the biggest providers of iot security today, and first to deliver a comprehensive security reference architecture for how to build-in security to make your iot systems “secure by design.” iot security is a complex problem requiring both breadth and depth of security experience. symantec brings an unrivaled breadth of leading security solutions for device protection, encryption, authentication, key management, and code signing. symantec also has unmatched depth in security expertise from monitoring, analyzing and processing more than 10 trillion security events per year worldwide for symantec’s global intelligence network.  this particular team is building an exciting new product to extend norton security to everything connected in the consumer home. with iot, the number of connected devices is growing at an exponential rate. while, these new devices offer a new range of possibilities, they also are increasing the attack vectors for the hackers exponentially. these devices collect a lot more sensitive personal data. securing these devices and the personal information has never been so crucial. the team is building disruptive next-gen iot security applications and product experience that encompass hardware, software, mobile apps and services.   also, this team is empowered for complete autonomy and ownership. it functions independently to find creative, bold & innovative solutions to solve some of the most complex problems in the iot space.   we are looking to leverage a sharp, passionate & experienced principal software engineer to build and protect the next generation of connected devices. these engineers will work with a team of world-class security experts to secure the connected consumer homes. these engineers will be part of a team of ninjas within symantec, who are focused on building innovative & disruptive applications in the internet of things space. the team operates like a startup within symantec.  as a principal data scientist, machine learning , the   below are needed to be successful:   responsibilities help our efforts to improve the way we gather and prepare data for analysis to help make critical feature decisions.apply statistical and machine learning techniques to identify new opportunities for actiondesign new tools and processes to enable better data modeling, analysis, and experimentationemploy machine learning to detect and correlate problemsbuild models, simulation, scalable and automated analytical systemsdrive improvements to the product design and architecture, leading to increased customer satisfactionlead and collaborate with experts from across the company to advance data science best practices qualifications background in computer science, electrical engineering, statistics, physics, mathematics, operations research or equivalent technical field, with phd or ms degree with 3+ years of machine learning experience in the industrysolid knowledge of machine learning and data mining techniques (classifications, regressions, anomaly detection, clustering, recommenders). working experience in solving real world machine learning problems. ability to formulate business requirements into machine learning problems, prototype statistical analysis and modeling algorithms and apply these algorithms for data driven solutions to problems in new domains. software development skills in one or more high level languages (c/c++/java), one or more scripting languages (python/perl/shell). preferred experience with agile principles and practices such as continuous integration, daily scrums, and sprint/release planning and execution. if you are passionate about building great products and are looking to join a high-performing, hyper-productive team? come join us and be part of a team that is being built as a “startup\" within symantec, offering the right blend of the passion of a startup and the stability of a big corporation.   #li-wp1  ====================\\u200b====================\\u200b  symantec is an equal opportunity employer. all candidates for employment will be considered without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, physical or mental disability, veteran status, or any other basis protected by applicable federal, state or local law. your goal – to improve the education process and better the lives of students -- through data science and machine learning. the organization: graph and modeling data and content are core to chegg: as a student hub, we want to ensure that students discover how things get connected – from a course they take to a skill they acquire to a career they pursue. to create the most relevant and engaging interaction, we are using a multitude of machine learning techniques so that we can better model student experience, link various types of content and provide a personalized experience. the role: staff data scientist – machine learning the staff data scientist focusing on machine learning will define, design and develop machine learned solutions at chegg. you will lead in identification and implementation of key projects to link various types of content and facilitate knowledge discovery. you will partner with the analytics and data engineering teams to deliver production-ready tools and packages.  responsibilities: develop highly scalable classifiers / predictors and tools leveraging machine/deep learning in cloud-based applications to improve chegg products and services take a lead role in the research and development of novel machine learning and analytical models and guide the development of data-driven products. identify key evaluation metrics and release requirements for products within chegg integrate new data and design workflows innovate, share and educate team members and community  requirements: msc. or phd. in computer science, engineering, statistics, computational linguistics 5 + years of experience in machine learning, deep learning, natural language processing, information retrieval, signal processing, recommendation systems strong programming skills in linux/unix scripting/python/r/java/scala hands-on experience with ml tools and libraries (e.g. scikit-learn, theano, tensorflow, caffe) experience using big data platforms (hadoop/mahout, spark/mllib). designing evaluation tasks for data science products, crowdsourcing experience building production-ready systems and/or incorporation ml solutions for customer-facing products ability to think about problems from a data perspective, establish conceptual connections to data sources, understand relationships among data, see the forest and the trees, be comfortable with uncertainties/approximations. excellent communication skills, curiosity and sense of humor  chegg out our culture and benefits! http://www.chegg.com/jobs/benefits https://www.youtube.com/watch?v=yyhnkwid7oo http://techblog.chegg.com/ job title : data scientist  location : sunnyvale, california  about us: appnomic systems is the one of the prominent players in application performance management (apm), offering solution on monitoring transactions, violations and services. appnomic products monitor every aspect of application performance, allowing it operations to deliver high performing, highly reliable, highly available enterprise applications. appnomic offers a near real-time global view of application performance and application errors across enterprise tech stack.  position overview: we’re looking for a data scientist to help us uncover insights that will shape the future of application performance management. you’ll analyze application transactions, key performance indicators (kpi) of software components, errors and violations data and provides useful insights to derive value from our data set. the successful candidate is an excellent communicator across business and technical teams.  responsibilities: uncover business and product opportunities by efficient and actionable analysis  work with teams across all functions (product, marketing, engineering)  help analyze the effectiveness of new features  identify new levers and measure the health of the infrastructure  make scientific contributions while providing thought leadership in publications, peer-reviewed publications, speaking opportunities, presentations  interact and collaborate with engineers, relaying feedback from customers to continually develop our product  requirements: curiosity: you’re interested in any problem where data can be applied  very comfortable coding: familiarity and experience with at least one of the following: python, r, spss  healthy skepticism: you understand the importance of vetting analysis to make sure data isn’t misrepresented  experience dealing with large data sets  strong grasp of statistics and exploratory data analysis  strong coding, data management and data extraction skills  proficient in at least one analysis tool/graphing library  strong verbal and written skills, ability to communicate effectively with all levels throughout the organization  experience contributing to the design and implementation of apm enterprise solutions is highly desirable  higher level degree in statistics or mathematics  apply now posting title project admin mgr - data analyst job description vmware is seeking a data analyst focused on engineering data analytics.  we will be building out a data warehouse like capability within product engineering to support all of engineering. the purpose of this data warehouse is to provide a single repository where all relevant data can be combined to enable analysis and reporting. this is a capability that does not exist today. what we have instead are a number of separate repositories, often aligned functionally / organizationally which have been created to support the particular function. this provides limited value. it may meet many of the needs of the function, but it does not allow for more broad, cross functional or full product lifecycle analysis.  this implementation will require a small team - possibly made up of staff that already exist within product engineering or more broadly at vmware. the actual structure of this team is still to be defined. in the short term, we need a resource that can help to pull together some of this cross functional, product lifecycle data and create some interim analysis.  the ideal candidate for this position has strong analytical skills, a solid math background, is inquisitive, has the capacity to understand engineering, test and other aspects of the software product lifecycle, takes direction but can work on their own, and loves a challenge!  responsibilities:  pull together data and turn it into useful information for the product organization analyze data and recommend additional views communicate findings effectively work well with others in defining needs and translating that into the approach to meeting them member of team that defines our data warehouse solution member of team that evaluates techologies  requirements:  college degree in math, economics or other data driven major prior experience analyzing data sharp, analytical, highly motivated bs in math, economics or related comfortable interacting with various levels of engineering capable of working independently why work for our division vmware’s world-class, award-winning r&d; team is comprised of thousands of top-notch computer scientists and software engineers that are transforming computing through virtualization. members of the r&d; team voice their creative ideas and watch them become initiatives, participate in exciting short-term and long-term products on the vmware roadmap, initiate advanced research projects, and/or write and test code that ships. at vmware, our engineers continue to learn and grow by working with top professionals from around the world and recent graduates of top universities and by taking advantage of our extensive internal training opportunities and generous external education assistance program. r&d; team members work on the latest computing equipment and have access to the acm and ieee libraries. vmware has r&d; offices in: silicon valley; burlington, ma; cambridge, ma; broomfield, co; sofia, bulgaria; aarhus, denmark; london, uk; herzliya, israel; bangalore, india; and beijing, china. advertised location (select only one location) palo alto, ca, us about us vmware is the leader in cloud infrastructure, business mobility and virtualization software. a pioneer in the use of virtualization and policy-driven automation technologies, vmware simplifies it complexity across the entire data center to the virtual workplace, empowering customers with solutions in the software-defined data center to hybrid cloud computing and the mobile workspace.  with 2014 revenues of $6.04 billion, vmware has more than 500,000 customers, 75,000 partners, and 18,000+ employees in 120+ locations around the world. at the core of what we do are our employees who deeply value execution, passion, integrity, customers, and community. want to be part of a compassionate community that thrives on architecting what\\'s next in it? learn more at vmware.com/careers. eeo statement vmware is an equal opportunity employer committed to the principles of equal employment opportunity and affirmative action for all applicants and employees. equal opportunity and consideration are afforded to all qualified applicants and employees in personnel actions, which include: recruiting and hiring, selection for training, promotion, rates of pay or other compensation, transfer, discipline, demotion, layoff or termination. vmware does not unlawfully discriminate on the basis of race, color, religion, sexual orientation, marital status, pregnancy, gender identity, gender expression, family medical history or genetic information, citizenship, national origin or ancestry, sex, age, physical or mental disability, medical condition, veteran status, military status, or any other basis protected by federal, state or local law, ordinance or regulation. vmware also makes reasonable accommodations for disabled employees consistent with applicable law. further, it is the policy of vmware to maintain a working environment free of all forms of harassment. requisition number 71929br advertised group (place a checkmark to select multiple groups) project/program manager job description: leverage machine learning techniques to discover data patterns and user behavior  evaluate scenarios, and predict future outcomes through statistical data modeling, big data, and optimization tools and techniques like bayesian modeling , mcmc based estimation methods, convolution-based methods, machine learning, random forests,decision trees, etc  use a combination of r, python, javascript, c, java, , sql, etc to solve problems and discover new solutions  translate ideas and theory into commercial solutions, while taking ownership of the process.  help shape our data infrastructure, reporting and analytics platforms  job requirements: 8+ years in the field of data science, data discovery and machine learning.  strong math background  familiarity with a variety of machine learning techniques and statistical methods  proficiency with machine learning techniques  strong db skills are a must, should be very strong with sql and nosql databases  proficient in hadoop, map/reduce, pig, scala, hive  experience with designing and building large scale data pipelines at large scale  extensive linux systems/shell programming experience  expertise in distributed/scalable systems and algorithms with awareness of time and space complexity  experience with handling and mining geospatial data  masters degree in computer science or equivalent job description  intel labs is seeking an experienced researcher in the area of visual computing within the visual computing lab.  in this position, you will be responsible for conceiving, researching, and prototyping new visual computing techniques. you will use your strong knowledge of mathematical and algorithmic techniques to identify and develop new methods in visual computing.  you must also possess strong verbal and written communication skills and a demonstrated ability to work in a team-oriented environment. you are expected to maintain substantial knowledge of state-of-the-art principles and theories, and to contribute regularly to scientific literature and the research community at large. qualifications you must possess the below minimum qualifications to be initially considered for this position. preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates. experience listed below would be obtained through a combination of your work experience, graduate school, post-doc research and/or relevant internship experiences. minimum qualifications:  must have already graduated with a phd in computer science, electrical engineering or similar technical discipline minimum of 2 years of research experience with two or more of the following areas: visual perception visual data processing machine learning machine reasoning motor control three-dimensional modeling optimization strong software engineering experience demonstrated through publicly available software systems high-level mathematical background at least 5 publications in first-tier, highly selective international conferences such as cvpr, iccv, eccv, icml, nips, or siggraph  preferred qualifications:  10+ publications in first-tier conferences other locations   requisition no.: 121376br  business title: engineer, structured data r&d; subsidiary: ebay primary job responsibilities: do you want to help the machines take over the world?  the structured data research and development team is tasked with taking ideas and prototypes in various machine learning disciplines and bringing them in front of users and customers. our main focus areas are machine learning, natural language processing and computer vision and we are continually expanding our reach. we are looking for engineers who love coding and learning new things.  on the day to day you will:  develop large-scale services that serve heavy traffic and participate in performance tuning to meet aggressive service level agreements. develop prototypes where necessary to prove the feasibility of various technology solutions. design, develop and test (including automated, continuous integration) key product features/components of our platform. develop systems that are highly reliable, scalable, but surprisingly easy to maintain. be independent in feature/component design and conduct effective peer code reviews where needed. be independent in feature/component design and conduct code reviews where needed. be an active participant in the architecture and design discussions. regularly collaborate within and across teams – applied scientists, ops, platform, dependent engineer groups, qe, external partners – to propose solutions, actively participate in the integration discussions and triage platform issues. continuously innovate through frequent product iterations (agile/scrum setup). participate in the developer community (internal and open source) to learn, share and grow to be an excellent technical expert and actively grow your career based on your career aspirations.  job requirements:you should be good at:  problem solving and coming up with creative solutions to tough challenges developing highly reliable, scalable real-time services, including sound knowledge of designing restful services continuous integration, maven, github and agile/scrum setup is preferred java with good object-oriented methodology, frameworks and development of complex modules communication and collaboration skills to participate & shape the architecture, high level and detailed designs of the systems design, development and testing of large and complex applications  it is great if you are interested in:  hadoop map/reduce, big data machine learning, deep learning nlp tools such as pos tagging, ner, stemming, parsing, wsd, sentence segmentation is highly preferred machine learning tools such as moses, mahout, sci-kit learn, caffe, sparkml, cuda, tensorflow, etc. bachelor’s degree, master\\'s preferred  secret underground lair not included. last updated: 02/25/2016 job description  the world continues to get “smaller” and “flatter.” but we see now that being connected isn’t enough. fortunately, something else is happening that holds new potential: the planet is becoming smarter. that is, intelligence is being infused into the way the world literally works — into the systems, processes and infrastructure that help billions of people work and live.across the world, a distinctly different group of leaders is announcing its arrival. they are making decisions based on evidence, not on habit or opinion or “gut.” they are anticipating, rather than merely reacting, to events. they are seizing competitive advantage, but at least as often, they are re-framing the issues--in unexpected, often counter-intuitive ways. for example, we used to schedule our road repairs. now we predict them. marketers used to see you as a \"segment.\" now they see you as you. law enforcement used to fight crime after the fact. now they work to prevent crimes before it breaks out. city leaders used to be judged by how they responded after a crisis. now they are judged by how well they anticipate one. ibm’s smarter planet journey began four years ago and took on added significance with the recently announced ibm research – africa lab in nairobi, kenya. this is the 12th ibm research lab and our first lab dedicated to a whole continent. the lab will be located on the campus of the catholic university in the karen-langata area in nairobi. our goal is to become a world-class research organization delivering innovations relevant to the african continent. in this regard, we are seeking research scientists to join us to realize our smarter planet agenda in africa. the successful candidates will develop technologies, analytics and algorithms in one of the following areas (inter alia): 1. smarter cities: research and development in technologies that will improve traffic flow, water management including water source (solar evaporation), distribution (high-precision weather modeling, water flow in ground and underground rivers), the effects of contamination, storage systems, the consumption of water, and energy (smart grid, renewable energy etc.)2. e-government: innovations in the areas of open data, shared services, public service delivery, security and analytics applications3. mobile commerce: develop mobile technologies that matter to the african market. qualifications  null  additional information  null responsibilities: kforce has a client that is seeking a data scientist in santa clara, california (ca).  about the role: in this role, the candidate will help support the client charter to transform the it industry by:  assisting with analytics planning, development and implementation creating algorithms for data detection working with the product team to develop custom solutions translating business requirements into technical specifications managing development teams to ensure proposed solutions are delivered  requirements: the perfect candidate for this role will have a demonstrated record of success in positions of increasing responsibility over the course of their career.  an ideal background will include:  a minimum of 2 years of experience experience with r programming a background in java, big data, python and apache spark a major plus in depth knowledge of data science principles and practices strong data analytic, predictive modeling and data analysis skills experience running data analytic projects excellent interpersonal, written and verbal communication skills   '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     job description  the medical sieve group in co...\n",
       "1     position : data scientist – modellerlocation :...\n",
       "2     description intuit quickbooks is on a mission ...\n",
       "3     (menlo park, ca) careers at oculus a facebook ...\n",
       "4     data scientist with pythonlocation: cupertino ...\n",
       "5     requisition no.: 121517br  subsidiary: ebay ma...\n",
       "6     requisition no.: 29374br  subsidiary: paypal  ...\n",
       "7     requisition no.: 119481br  subsidiary: ebay ma...\n",
       "8     position: data scientist / big data engineer –...\n",
       "9     discovering the perfect course is the first an...\n",
       "10    requisition id: 105756 work area: software-des...\n",
       "11    additional location(s) or information: job cat...\n",
       "12    about retail solutions, inc.: retail solutions...\n",
       "13    the bioinformatics, data analysis and statisti...\n",
       "14    the role  play a central role in designing and...\n",
       "15    requisition no.: 29268br  subsidiary: paypal  ...\n",
       "16    as a leading fortune 500 technology & security...\n",
       "17    your goal – to improve the education process a...\n",
       "18    job title : data scientist  location : sunnyva...\n",
       "19    posting title project admin mgr - data analyst...\n",
       "20    job description: leverage machine learning tec...\n",
       "21    job description  intel labs is seeking an expe...\n",
       "22    requisition no.: 121376br  business title: eng...\n",
       "23    job description  the world continues to get “s...\n",
       "24    responsibilities: kforce has a client that is ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description.apply(lambda t: t.lower() + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61792"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_word_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 466),\n",
       " ('the', 250),\n",
       " ('to', 229),\n",
       " ('of', 210),\n",
       " ('in', 172),\n",
       " ('data', 159),\n",
       " ('a', 144),\n",
       " ('with', 128),\n",
       " ('is', 72),\n",
       " ('for', 72),\n",
       " ('or', 70),\n",
       " ('experience', 63),\n",
       " ('on', 52),\n",
       " ('are', 50),\n",
       " ('machine', 48),\n",
       " ('our', 46),\n",
       " ('as', 42),\n",
       " ('you', 41),\n",
       " ('team', 41),\n",
       " ('will', 41),\n",
       " ('that', 40),\n",
       " ('be', 38),\n",
       " ('product', 34),\n",
       " ('strong', 33),\n",
       " ('work', 33),\n",
       " ('at', 33),\n",
       " ('learning', 32),\n",
       " ('business', 28),\n",
       " ('solutions', 27),\n",
       " ('we', 25),\n",
       " ('software', 25),\n",
       " ('new', 24),\n",
       " ('more', 22),\n",
       " ('research', 22),\n",
       " ('this', 22),\n",
       " ('an', 22),\n",
       " ('knowledge', 20),\n",
       " ('analysis', 20),\n",
       " ('statistical', 20),\n",
       " ('working', 20),\n",
       " ('scientist', 20),\n",
       " ('skills', 20),\n",
       " ('develop', 20),\n",
       " ('other', 20),\n",
       " ('building', 19),\n",
       " ('job', 19),\n",
       " ('engineering', 19),\n",
       " ('computer', 18),\n",
       " ('have', 18),\n",
       " ('by', 18),\n",
       " ('using', 18),\n",
       " ('from', 18),\n",
       " ('technical', 18),\n",
       " ('years', 18),\n",
       " ('development', 18),\n",
       " ('ability', 18),\n",
       " ('your', 17),\n",
       " ('large', 17),\n",
       " ('&', 17),\n",
       " ('into', 17),\n",
       " ('one', 16),\n",
       " ('background', 15),\n",
       " ('big', 15),\n",
       " ('responsibilities:', 15),\n",
       " ('analytics', 15),\n",
       " ('such', 15),\n",
       " ('teams', 15),\n",
       " ('products', 15),\n",
       " ('science', 15),\n",
       " ('highly', 14),\n",
       " ('complex', 14),\n",
       " ('help', 14),\n",
       " ('it', 13),\n",
       " ('design', 13),\n",
       " ('quality', 13),\n",
       " ('security', 13),\n",
       " ('systems', 13),\n",
       " ('applications', 13),\n",
       " ('communication', 13),\n",
       " ('management', 13)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(subject_word_bag.split()).most_common()[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = [word for word in stopwords.words('english')] + ['re:', 'fwd:', '-', '•']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 159),\n",
       " ('experience', 63),\n",
       " ('machine', 48),\n",
       " ('team', 41),\n",
       " ('product', 34),\n",
       " ('strong', 33),\n",
       " ('work', 33),\n",
       " ('learning', 32),\n",
       " ('business', 28),\n",
       " ('solutions', 27),\n",
       " ('software', 25),\n",
       " ('new', 24),\n",
       " ('research', 22),\n",
       " ('knowledge', 20),\n",
       " ('analysis', 20),\n",
       " ('statistical', 20),\n",
       " ('working', 20),\n",
       " ('scientist', 20),\n",
       " ('skills', 20),\n",
       " ('develop', 20),\n",
       " ('building', 19),\n",
       " ('job', 19),\n",
       " ('engineering', 19),\n",
       " ('computer', 18),\n",
       " ('using', 18),\n",
       " ('technical', 18),\n",
       " ('years', 18),\n",
       " ('development', 18),\n",
       " ('ability', 18),\n",
       " ('large', 17),\n",
       " ('&', 17),\n",
       " ('one', 16),\n",
       " ('background', 15),\n",
       " ('big', 15),\n",
       " ('responsibilities:', 15),\n",
       " ('analytics', 15),\n",
       " ('teams', 15),\n",
       " ('products', 15),\n",
       " ('science', 15),\n",
       " ('highly', 14),\n",
       " ('complex', 14),\n",
       " ('help', 14),\n",
       " ('design', 13),\n",
       " ('quality', 13),\n",
       " ('security', 13),\n",
       " ('systems', 13),\n",
       " ('applications', 13),\n",
       " ('communication', 13),\n",
       " ('management', 13),\n",
       " ('related', 13),\n",
       " ('learning,', 13),\n",
       " ('retail', 12),\n",
       " ('candidate', 12),\n",
       " ('techniques', 12),\n",
       " ('understanding', 12),\n",
       " ('sql', 11),\n",
       " ('programming', 11),\n",
       " ('analytical', 11),\n",
       " ('tools', 11),\n",
       " ('and/or', 11),\n",
       " ('–', 11),\n",
       " ('science,', 11),\n",
       " ('insights', 11),\n",
       " ('computing', 10),\n",
       " ('models', 10),\n",
       " ('understand', 10),\n",
       " ('requirements:', 10),\n",
       " ('written', 10),\n",
       " ('customers', 10),\n",
       " ('vmware', 10),\n",
       " ('preferred', 10),\n",
       " ('across', 10),\n",
       " ('statistics,', 10),\n",
       " ('algorithms', 10),\n",
       " ('information', 10),\n",
       " ('deliver', 10),\n",
       " ('/', 10),\n",
       " ('within', 10),\n",
       " ('degree', 10),\n",
       " ('various', 10),\n",
       " ('identify', 9),\n",
       " ('predictive', 9),\n",
       " ('improve', 9),\n",
       " ('also', 9),\n",
       " ('provide', 9),\n",
       " ('operations', 9),\n",
       " ('us', 9),\n",
       " ('performance', 9),\n",
       " ('looking', 9),\n",
       " ('build', 9),\n",
       " ('requirements', 9),\n",
       " ('qualifications', 9),\n",
       " ('key', 9),\n",
       " ('application', 9),\n",
       " ('skills,', 9),\n",
       " ('global', 8),\n",
       " ('ideal', 8),\n",
       " ('like', 8),\n",
       " ('areas', 8),\n",
       " ('opportunity', 8)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_words = [word for word in subject_word_bag.split() if word.lower() not in stops]\n",
    "Counter(subject_words).most_common()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5c810c446054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create the pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'user_id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"visits\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mvisits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_purchases'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtotal_purchases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time_max\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtime_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time_min\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtime_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time_diff\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtime_diff\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# In[10]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Convert panadas elements to the proper types.  Put in columns for normalized variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_purchases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_purchases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_id' is not defined"
     ]
    }
   ],
   "source": [
    "    #Create the pandas dataframe\n",
    "    df = pd.DataFrame({'user_id' : user_id, \"visits\" : visits, 'total_purchases' : total_purchases, \"time_max\" : time_max, \"time_min\" : time_min, \"time_diff\" : time_diff})\n",
    "    # In[10]:\n",
    "    #Convert panadas elements to the proper types.  Put in columns for normalized variables.\n",
    "    df[['total_purchases']]=df[['total_purchases']].astype(float)\n",
    "    df[['user_id']]=df[['user_id']].astype(object)\n",
    "    # In[11]:\n",
    "    df['norm_max_time']=(df['time_max']-df['time_max'].mean())/(df['time_max'].max()-df['time_max'].min())\n",
    "    # In[12]:\n",
    "    df['norm_visits'] = (df['visits']-df['visits'].mean())/(df['visits'].max()-df['visits'].min())\n",
    "    # In[13]:\n",
    "    df['norm_total_purchases'] = (df['total_purchases']-df['total_purchases'].mean())/(df['total_purchases'].max()-df['total_purchases'].min())\n",
    "    # In[17]:\n",
    "    #class sklearn.cluster.KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances=True, verbose=0, random_state=None, copy_x=True, n_jobs=1)\n",
    "    df[[6,7,8]].dtypes\n",
    "    # In[18]:\n",
    "    kmeans = KMeans(init ='k-means++', n_clusters = 4, n_init=10)\n",
    "    #kmeans.fit(df)\n",
    "    kmeans.fit(df[[6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-ec6c88654d29>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-ec6c88654d29>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    results[0].\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "results[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c4d080e17027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    " r = requests.get(url[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.indeed.com/viewjob?jk=d73f090a45bd5232&qd=VJkvx8ARkUg4BTzBiPO74cOFQXA2SP39qeq0wN3mseLtI7ek5yI-2YCaRF90c_BlcRasNhazbz6_Wn8NDNbc7Ezd4EiRwSt1SnrSMsGpDG61ejuS5zYC3b4ikRuO41LG&indpubnum=8538934413867228&atk=1agvljgctb050fok'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-30c4a61b2c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "page = requests.get(url[2].text)\n",
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-f0b77a89f2de>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-f0b77a89f2de>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (We need to use page.content rather than page.text because html.fromstring implicitly expects bytes as input.)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(We need to use page.content rather than page.text because html.fromstring implicitly expects bytes as input.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a7955749e6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-b854f42b6b8d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-b854f42b6b8d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <div title=\"buyer-name\">Carson Busses</div>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<div title=\"buyer-name\">Carson Busses</div>\n",
    "<span class=\"item-price\">$29.95</span>\n",
    "Knowing this we can create the correct XPath query and use the lxml xpath function like this:\n",
    "\n",
    "#This will create a list of buyers:\n",
    "buyers = tree.xpath('//div[@title=\"buyer-name\"]/text()')\n",
    "#This will create a list of prices\n",
    "prices = tree.xpath('//span[@class=\"item-price\"]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0daa383740c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#<span id=\"job_summary\" class=\"summary\">\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//span[@id=\"job_summary\"]/text()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "#<span id=\"job_summary\" class=\"summary\">\n",
    "summary = tree.xpath('//span[@id=\"job_summary\"]/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b2e36fe65e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Summary: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "print('Summary: ', summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-80295fc5928b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s - %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "for element in tree.iter():\n",
    "...     print(\"%s - %s\" % (element.tag, element.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d260c9b6b91d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\w+class=\"summary\">(\\d+)</span>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "m = re.search('\\w+class=\"summary\">(\\d+)</span>', r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f1efe25c2ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'class=\"summary\\\">(.+)\\<\\/span>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "m = re.search(r'class=\"summary\\\">(.+)\\<\\/span>', r.text,re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-082decdb7f61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'</span>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "m = re.search(r'</span>', r.text)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                    '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6ba4da0a43c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'class=\"summary\\\">(.+)/span>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "m = re.search(r'class=\"summary\\\">(.+)/span>', r.text,re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-69b64623f86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c6ebaf1e4dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a6cd9f65db92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'job_summary([^<]+)<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "m = re.search(r'job_summary([^<]+)<', r.text,re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-97257b49ca3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<title[^>]*>([^<]+)</title>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "m = re.search(r'<title[^>]*>([^<]+)</title>',r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-e314b4603708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-323bb043ec77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"job_summary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "r = requests.get(url[0].text)\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "text=soup.find(id=\"job_summary\").get_text().replace('\\n',' ')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prog_lang_dict = Counter({'R':doc_frequency['r'], 'Python':doc_frequency['python'],'Java':doc_frequency['java'], 'C++':doc_frequency['c++'],'Ruby':doc_frequency['ruby'],\n",
    "                    'Perl':doc_frequency['perl'], 'Matlab':doc_frequency['matlab'],\n",
    "                    'JavaScript':doc_frequency['javascript'], 'Scala': doc_frequency['scala']})\n",
    "\n",
    "analysis_tool_dict = Counter({'Excel':doc_frequency['excel'],  'Tableau':doc_frequency['tableau'],\n",
    "                        'D3.js':doc_frequency['d3.js'], 'SAS':doc_frequency['sas'],\n",
    "                        'SPSS':doc_frequency['spss'], 'D3':doc_frequency['d3']})  \n",
    "\n",
    "hadoop_dict = Counter({'Hadoop':doc_frequency['hadoop'], 'MapReduce':doc_frequency['mapreduce'],\n",
    "                'Spark':doc_frequency['spark'], 'Pig':doc_frequency['pig'],\n",
    "                'Hive':doc_frequency['hive'], 'Shark':doc_frequency['shark'],\n",
    "                'Oozie':doc_frequency['oozie'], 'ZooKeeper':doc_frequency['zookeeper'],\n",
    "                'Flume':doc_frequency['flume'], 'Mahout':doc_frequency['mahout']})\n",
    "\n",
    "database_dict = Counter({'SQL':doc_frequency['sql'], 'NoSQL':doc_frequency['nosql'],\n",
    "                    'HBase':doc_frequency['hbase'], 'Cassandra':doc_frequency['cassandra'],\n",
    "                    'MongoDB':doc_frequency['mongodb']})\n",
    "\n",
    "\n",
    "overall_total_skills = prog_lang_dict + analysis_tool_dict + hadoop_dict + database_dict # Combine our Counter objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import collocations\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a12a572bab95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[0;32m    105\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "nltk.word_tokenize(df.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first= df.description.apply(lambda t: t.lower() + \" \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c2d8b63e8eef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msecond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[0;32m    105\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "second=nltk.word_tokenize(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a879a421cd3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[0;32m    105\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "nltk.bigrams(nltk.word_tokenize(first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-71446a99efa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmytext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This is my sentance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[0;32m    105\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Vivek/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "mytext=nltk.word_tokenize(\"This is my sentance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(nltk.bigrams(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.bigrams(\"This is my sentance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second.dispersion_plot(['Statistics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(nltk.bigrams(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nextText = \"my sentance is good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(nltk.bigrams(nltk.word_tokenize(nextText)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(first)\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.dispersion_plot(['intuit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>expired</th>\n",
       "      <th>indeedApply</th>\n",
       "      <th>jobkey</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 19 Mar 2016 01:21:01 GMT</td>\n",
       "      <td>Data Scientist - 43275  Description</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>60351a8c21c7ea69</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Advanced statistical modeling, machine learnin...</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Genesis Global Management Coporation</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 18 Mar 2016 17:09:03 GMT</td>\n",
       "      <td>Must-Haves5+ years data science experienceDegr...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>b96e8049255fb8bc</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Experience coding in Python, R, or Clojure to ...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Insync Consulting Services</td>\n",
       "      <td>US</td>\n",
       "      <td>Mon, 21 Mar 2016 21:16:01 GMT</td>\n",
       "      <td>As our company's first data scientist, you’ll ...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>c584e9cc43bcb0fa</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Data Scientist experience:. Coding in Python, ...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mountain View</td>\n",
       "      <td>UserTesting</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 24 Mar 2016 03:06:08 GMT</td>\n",
       "      <td>Job Description  What makes the difference bet...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>ae4133ed7f8423de</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.384617</td>\n",
       "      <td>-122.08242</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>A given day could have you doing Machine Learn...</td>\n",
       "      <td>UserTesting</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cupertino</td>\n",
       "      <td>Reveille technologies</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 16 Mar 2016 15:20:23 GMT</td>\n",
       "      <td>Data Scientist: - Candidate should have a stro...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>4438dc8a975bda84</td>\n",
       "      <td>Data Scientist:</td>\n",
       "      <td>37.32143</td>\n",
       "      <td>-122.02747</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Candidate should have worked on different algo...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>TiVo</td>\n",
       "      <td>US</td>\n",
       "      <td>Sun, 20 Mar 2016 06:55:32 GMT</td>\n",
       "      <td>Support both internal and external client init...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>b976a589270769c2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.4001</td>\n",
       "      <td>-121.89531</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Working with a team of data engineers and data...</td>\n",
       "      <td>TiVo</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>EBay</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 03:48:17 GMT</td>\n",
       "      <td>Requisition No.: 121517BR  Subsidiary: eBay Ma...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f87400e4ba147c37</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>The ideal candidate is an independent, solutio...</td>\n",
       "      <td>Ebay</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>US</td>\n",
       "      <td>Mon, 07 Mar 2016 12:44:55 GMT</td>\n",
       "      <td>Role : FTE ( Full Time Employment)Year of expe...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>9ee83a44bc428657</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Apply Data Science and Machine Learning to a v...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>TCS</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 16 Mar 2016 15:20:56 GMT</td>\n",
       "      <td>- Candidate should have a strong background an...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>d36adf11e3e115ea</td>\n",
       "      <td>Data Scientist - Sunnyvale, CA</td>\n",
       "      <td>37.368134</td>\n",
       "      <td>-122.03297</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Strength in Machine Learning, Statistical Mode...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 16 Mar 2016 05:03:33 GMT</td>\n",
       "      <td>Netflix is seeking an outgoing, curious, inter...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>2ad11d20dd1131bf</td>\n",
       "      <td>Senior Data Scientist - Machine Learning Research</td>\n",
       "      <td>37.225273</td>\n",
       "      <td>-121.97253</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>As a senior data scientist, you will:. Bring a...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Rennick Barrett</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 08 Mar 2016 22:01:28 GMT</td>\n",
       "      <td>What client looking for?The ideal candidate ha...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>4350d3eaca1309a3</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Work collaboratively in a cross functional fea...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>T&amp;M Consulting Inc (A Michigan Based Company)</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 19 Mar 2016 10:33:39 GMT</td>\n",
       "      <td>T&amp;M; Consulting Inc (A Michigan Based Company)...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>1bcf0b3d646b66ff</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.368134</td>\n",
       "      <td>-122.03297</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Candidate should have worked on different algo...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Danaher Labs</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 24 Mar 2016 00:31:43 GMT</td>\n",
       "      <td>-  DAN000446  About Us  Launching in 2014, Dan...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>a0bc2cca3f4c4157</td>\n",
       "      <td>Data Scientist - Danaher Labs, Santa Clara, CA</td>\n",
       "      <td>37.35165</td>\n",
       "      <td>-121.95055</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Danaher Labs is seeking a Data Scientist who i...</td>\n",
       "      <td>Danaher</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Groupon</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 23 Mar 2016 06:45:50 GMT</td>\n",
       "      <td>Are you passionate about solving interesting a...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>b9f59065003e5882</td>\n",
       "      <td>Data Scientist, Local Intelligence</td>\n",
       "      <td>37.42517</td>\n",
       "      <td>-122.13624</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Strong analytical background, at least a BS, a...</td>\n",
       "      <td>Groupon</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Fanatics Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 15 Mar 2016 17:00:37 GMT</td>\n",
       "      <td>MTS 1, Data ScientistJob DescriptionAt Fanatic...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>1f90af91dcf964a5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.365383</td>\n",
       "      <td>-122.03297</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Experience developing machine learning, NLP an...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 25 Mar 2016 12:43:58 GMT</td>\n",
       "      <td>This position's primary focus is to manipulate...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>a1281b7096145fd1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.399815</td>\n",
       "      <td>-122.13571</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Individuals within the Data Scientist role are...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Myresource</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 22 Mar 2016 14:53:46 GMT</td>\n",
       "      <td>5+ years data science experienceDegree in phys...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>e90f3333dafb2742</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14835</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Experience coding in Python, R, or Clojure to ...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Zamplus Technology</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 17 Mar 2016 01:59:03 GMT</td>\n",
       "      <td>Job Requirement: 1/ Gather and analyze data, i...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>e4c8afe8b782e7dc</td>\n",
       "      <td>Machine Learning and Data Scientist</td>\n",
       "      <td>37.35165</td>\n",
       "      <td>-121.95055</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>1/ Gather and analyze data, identify key predi...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Premium Candidates</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 24 Mar 2016 01:59:40 GMT</td>\n",
       "      <td>Our Client is looking to Direct Hire a Data Sc...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>2c59d3de0c872cb8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Experience coding in Python, R, or Clojure to ...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Orzota, Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 23 Mar 2016 04:45:33 GMT</td>\n",
       "      <td>Looking for a strong data scientist to work at...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>5a6793c9d9070b26</td>\n",
       "      <td>Data Scientist with Big Data background</td>\n",
       "      <td>37.35165</td>\n",
       "      <td>-121.95055</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>1+ years of experience in big data projects as...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 16 Mar 2016 05:03:11 GMT</td>\n",
       "      <td>Netflix is seeking a talented and versatile da...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>7a1aa35ecb6794b9</td>\n",
       "      <td>Senior Data Scientist - Algorithm Experimentation</td>\n",
       "      <td>37.225273</td>\n",
       "      <td>-121.97253</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Proficiency with a statistical analysis tool s...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Citrix</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 06:00:09 GMT</td>\n",
       "      <td>We believe work is not a place, but rather a t...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>6588901dac07bbd5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.40236</td>\n",
       "      <td>-121.97912</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>R2283 Data Scientist (Open). Connect with inte...</td>\n",
       "      <td>Citrix Systems, Inc.</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 15 Mar 2016 22:56:56 GMT</td>\n",
       "      <td>Netflix is revolutionizing entertainment. We d...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>593dfe304f003ab7</td>\n",
       "      <td>Senior Data Scientist - Streaming Experimentat...</td>\n",
       "      <td>37.225273</td>\n",
       "      <td>-121.97253</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>4+ years relevant experience with a proven tra...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 16 Mar 2016 05:03:48 GMT</td>\n",
       "      <td>Netflix is revolutionizing entertainment. We d...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f6e7ecdc7a0ae6b1</td>\n",
       "      <td>Senior Data Scientist - Streaming Science &amp; Al...</td>\n",
       "      <td>37.225273</td>\n",
       "      <td>-121.97253</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Expertise in machine learning, Natural Languag...</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Orbital Insight</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 17 Mar 2016 02:34:20 GMT</td>\n",
       "      <td>Data Scientist   Our mission is to turn Geospa...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>e5d62cd4046669e3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.414837</td>\n",
       "      <td>-122.13187</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Along with our team of data scientists, you’ll...</td>\n",
       "      <td>Orbital Insight</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Danaher Labs</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 24 Mar 2016 00:31:43 GMT</td>\n",
       "      <td>-  DAN000446  About Us  Launching in 2014, Dan...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>a0bc2cca3f4c4157</td>\n",
       "      <td>Data Scientist - Danaher Labs, Santa Clara, CA</td>\n",
       "      <td>37.35165</td>\n",
       "      <td>-121.95055</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Danaher Labs is seeking a Data Scientist who i...</td>\n",
       "      <td>Danaher</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Citrix</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 06:00:09 GMT</td>\n",
       "      <td>We believe work is not a place, but rather a t...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>6588901dac07bbd5</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.40236</td>\n",
       "      <td>-121.97912</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>R2283 Data Scientist (Open). Connect with inte...</td>\n",
       "      <td>Citrix Systems, Inc.</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>IBM</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 18 Mar 2016 03:06:02 GMT</td>\n",
       "      <td>Job Description  Energy Storage Science and So...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>c6b10d54a5e7598d</td>\n",
       "      <td>Research Scientists-Energy Storage Science and...</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Energy Storage Science and Solutions group at ...</td>\n",
       "      <td>IBM</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>TiVo</td>\n",
       "      <td>US</td>\n",
       "      <td>Sun, 20 Mar 2016 06:55:32 GMT</td>\n",
       "      <td>Support both internal and external client init...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>b976a589270769c2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.4001</td>\n",
       "      <td>-121.89531</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Working with a team of data engineers and data...</td>\n",
       "      <td>TiVo</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Bloom Consulting Services, LLC.</td>\n",
       "      <td>US</td>\n",
       "      <td>Mon, 14 Mar 2016 18:09:12 GMT</td>\n",
       "      <td>Position: Data Scientist (Modeler)Duration: Fu...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>3fc44bc38fa81e82</td>\n",
       "      <td>Data Scientist (Modeler)</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Data Scientist (Modeler)*. Need someone with s...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>Earlens</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 23 Mar 2016 11:16:51 GMT</td>\n",
       "      <td>Clinical Menlo Park, CA JOB DESCRIPTION  About...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>2710948526dcccc2</td>\n",
       "      <td>Hearing Scientist</td>\n",
       "      <td>37.48045</td>\n",
       "      <td>-122.18158</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>The hearing scientist reports into the Directo...</td>\n",
       "      <td>StartUpHire</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Elti Solutions</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 03:17:10 GMT</td>\n",
       "      <td>A generously funded (more than $13 mln in seed...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>532f0c302afa2e06</td>\n",
       "      <td>Senior Frontend Engineer, Inference Platform</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Opportunity to work on a small team of ~10 ama...</td>\n",
       "      <td>Elti Solutions</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:38:41 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>9f302cd0cee873eb</td>\n",
       "      <td>Summer Internship: Exploring the feasibility o...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Fremont</td>\n",
       "      <td>Ardelyx</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 08 Mar 2016 11:25:35 GMT</td>\n",
       "      <td>Ardelyx? is a rapidly emerging biotech company...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>903c192565590f77</td>\n",
       "      <td>Scientist- Pharmaceutical Analysis</td>\n",
       "      <td>37.557503</td>\n",
       "      <td>-122.064125</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Independently interpret and present data to a ...</td>\n",
       "      <td>StartUpHire</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Elti Solutions</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 03:17:09 GMT</td>\n",
       "      <td>A generously funded (more than $13 mln in seed...</td>\n",
       "      <td>false</td>\n",
       "      <td>true</td>\n",
       "      <td>2aae29e6f07f2a48</td>\n",
       "      <td>Senior Software Engineer, Inference Platform d...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Opportunity to work on a small team of ~10 ama...</td>\n",
       "      <td>Elti Solutions</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Mountain View</td>\n",
       "      <td>Symantec</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 18 Mar 2016 00:16:05 GMT</td>\n",
       "      <td>Symantec Website Security</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>6f7c0944ef37ce0b</td>\n",
       "      <td>Director of Revenue Operations</td>\n",
       "      <td>37.384617</td>\n",
       "      <td>-122.08242</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Symantec Website SecurityDelivering Confidence...</td>\n",
       "      <td>Symantec</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:35 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f068b7ba3b4fa5d0</td>\n",
       "      <td>Summer Internship: Assessment of high-throughp...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Cepheid</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 01 Mar 2016 03:19:40 GMT</td>\n",
       "      <td>Start your career with us today and make a big...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>3ebac3961bfa14e8</td>\n",
       "      <td>Software Quality Engineering Intern</td>\n",
       "      <td>37.368134</td>\n",
       "      <td>-122.03297</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>You will collaborate with the Software Enginee...</td>\n",
       "      <td>Cepheid</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Stanford</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 26 Mar 2016 01:42:09 GMT</td>\n",
       "      <td>As the oldest medical school in the western Un...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>7328caed6071e70f</td>\n",
       "      <td>Human Resources Administrator 1</td>\n",
       "      <td>37.4282</td>\n",
       "      <td>-122.1775</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>As the oldest medical school in the western Un...</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Stanford Health Care</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 17 Mar 2016 07:08:50 GMT</td>\n",
       "      <td>The Stanford Cancer Center is expanding its fa...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>bc5009434bbf1b80</td>\n",
       "      <td>Clinical Lab Scientist Relief (Chem/Coag/Hem) ...</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Recognized for advanced clinical care, scienti...</td>\n",
       "      <td>HEALTHeCAREERS Network</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Fremont</td>\n",
       "      <td>Ardelyx</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 08 Mar 2016 11:26:08 GMT</td>\n",
       "      <td>Department: Translational Biology Reports to: ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>7fc3717d282f96bb</td>\n",
       "      <td>Bioinformatics Scientist</td>\n",
       "      <td>37.557503</td>\n",
       "      <td>-122.064125</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Scientists, advanced thinkers, and people who ...</td>\n",
       "      <td>StartUpHire</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:52 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>a2aa53056f16e68e</td>\n",
       "      <td>Summer Internship: Assessment and evaluation o...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Fremont</td>\n",
       "      <td>Ardelyx</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 08 Mar 2016 11:26:07 GMT</td>\n",
       "      <td>We are currently seeking a Principal Investiga...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>833b4632a743be2e</td>\n",
       "      <td>Principal Investigator - Cardiorenal Disease</td>\n",
       "      <td>37.557503</td>\n",
       "      <td>-122.064125</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Assist the clinical development team in provid...</td>\n",
       "      <td>StartUpHire</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:35 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>7c247470cff1e08c</td>\n",
       "      <td>Summer Internship: Evaluating Protein Solubili...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 02 Mar 2016 17:57:46 GMT</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f08a37748b6092fc</td>\n",
       "      <td>Associate/Engineer/Scientist</td>\n",
       "      <td>37.481056</td>\n",
       "      <td>-122.17388</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>This position requires some travel and will in...</td>\n",
       "      <td>Exponent</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:35 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>25b8955b4fdeee63</td>\n",
       "      <td>Summer Internship: IB Regulatory Building Bloc...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Milpitas</td>\n",
       "      <td>KLA - Tencor</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 19 Mar 2016 00:07:54 GMT</td>\n",
       "      <td>Position : Senior Research Scientist Location ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>a09c72c7e446ee5a</td>\n",
       "      <td>Senior Research Scientist ( C++ | Object Orien...</td>\n",
       "      <td>37.436813</td>\n",
       "      <td>-121.88461</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Computational physics, scientific programming,...</td>\n",
       "      <td>Monster</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Tyco</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 08 Mar 2016 23:50:11 GMT</td>\n",
       "      <td>Tyco (NYSE: TYC) is the world’s largest pure-p...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>2cbc49400113667f</td>\n",
       "      <td>Sr. Software Engineer-Computer Vision, Tyco Te...</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Embedded Vision Systems – imagers, video and s...</td>\n",
       "      <td>Tyco</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Tyco</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 08 Mar 2016 23:50:11 GMT</td>\n",
       "      <td>Tyco (NYSE: TYC) is the world’s largest pure-p...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>2cbc49400113667f</td>\n",
       "      <td>Sr. Software Engineer-Computer Vision, Tyco Te...</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.89011</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Embedded Vision Systems – imagers, video and s...</td>\n",
       "      <td>Tyco</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Embedded Resource Group</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 02 Mar 2016 22:05:05 GMT</td>\n",
       "      <td>UX Designer  UX design for applications dealin...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>e405c6c4182c6253</td>\n",
       "      <td>UX Designer (4712)</td>\n",
       "      <td>37.406593</td>\n",
       "      <td>-122.15385</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Research scientists, UI and 3D artists, intera...</td>\n",
       "      <td>Monster</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Jazz Pharmaceuticals, Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 22 Mar 2016 23:32:43 GMT</td>\n",
       "      <td>Jazz Pharmaceuticals is seeking a clinical sci...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>f3ad03b1c0015e99</td>\n",
       "      <td>Clinical Scientist, Sleep Development, Clin De...</td>\n",
       "      <td>37.406998</td>\n",
       "      <td>-122.14846</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Read and interpret scientific and medical lite...</td>\n",
       "      <td>DeviceSpace.com</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Milpitas</td>\n",
       "      <td>KLA - Tencor</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 19 Mar 2016 00:07:54 GMT</td>\n",
       "      <td>Position : Senior Research Scientist Location ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>a09c72c7e446ee5a</td>\n",
       "      <td>Senior Research Scientist ( C++ | Object Orien...</td>\n",
       "      <td>37.436813</td>\n",
       "      <td>-121.88461</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Computational physics, scientific programming,...</td>\n",
       "      <td>Monster</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:35 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>e51c1ce70d27cf3d</td>\n",
       "      <td>Summer Internship: Metabolomics analysis of Ba...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:53 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>d7c77cda32583af2</td>\n",
       "      <td>Summer Internship: Evaluating bioreactor syste...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:34 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>63e63d09b0956010</td>\n",
       "      <td>Summer Internship: Testing Feasibility of a Ba...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 05 Mar 2016 01:37:53 GMT</td>\n",
       "      <td>Here is a learning environment like no other! ...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>31d9e016c940bb59</td>\n",
       "      <td>Summer Internship: Predicting Protein Solubili...</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>DuPont Industrial Biosciences strongly believe...</td>\n",
       "      <td>DuPont</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Milpitas</td>\n",
       "      <td>KLA - Tencor</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 10 Mar 2016 02:01:11 GMT</td>\n",
       "      <td>Job Description :Business Unit: The Film and S...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>7e2480b2a577ec91</td>\n",
       "      <td>Sr. Software Engineer ( C++ | OO | Computation...</td>\n",
       "      <td>37.436813</td>\n",
       "      <td>-121.88461</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Computational physics, scientific programming,...</td>\n",
       "      <td>Monster</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Infer</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 01 Mar 2016 07:16:46 GMT</td>\n",
       "      <td>We are looking for a senior data scientist wit...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>37d37eee0c0a3fad</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>We are looking for a senior data scientist wit...</td>\n",
       "      <td>VentureLoop</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>HealthTap</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 07:25:58 GMT</td>\n",
       "      <td>HealthTap is taking off!  As Data Scientist ea...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>ac7f7e283bc6cc36</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.43956</td>\n",
       "      <td>-122.14286</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Solid grounding in applied mathematics and sta...</td>\n",
       "      <td>VentureLoop</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Ambarella</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 02 Mar 2016 07:20:10 GMT</td>\n",
       "      <td>Microcode engineers at Ambarella are responsib...</td>\n",
       "      <td>false</td>\n",
       "      <td>false</td>\n",
       "      <td>dd7d8dda2f68a3be</td>\n",
       "      <td>Software Engineer - Microcode Group (Job#1188)</td>\n",
       "      <td>37.37544</td>\n",
       "      <td>-121.99687</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Develop a deep understanding of Ambarellaâs ...</td>\n",
       "      <td>VentureLoop</td>\n",
       "      <td>false</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              city                                        company country  \\\n",
       "0         San Jose                                          Adobe      US   \n",
       "1        Palo Alto           Genesis Global Management Coporation      US   \n",
       "2        Palo Alto                     Insync Consulting Services      US   \n",
       "3    Mountain View                                    UserTesting      US   \n",
       "4        Cupertino                          Reveille technologies      US   \n",
       "5         San Jose                                           TiVo      US   \n",
       "6         San Jose                                           EBay      US   \n",
       "7         San Jose                               HCL Technologies      US   \n",
       "8        Sunnyvale                                            TCS      US   \n",
       "9        Los Gatos                                        Netflix      US   \n",
       "10        San Jose                                Rennick Barrett      US   \n",
       "11       Sunnyvale  T&M Consulting Inc (A Michigan Based Company)      US   \n",
       "12     Santa Clara                                   Danaher Labs      US   \n",
       "13       Palo Alto                                        Groupon      US   \n",
       "14       Sunnyvale                                  Fanatics Inc.      US   \n",
       "15       Palo Alto                                        Infosys      US   \n",
       "16       Palo Alto                                     Myresource      US   \n",
       "17     Santa Clara                             Zamplus Technology      US   \n",
       "18       Palo Alto                             Premium Candidates      US   \n",
       "19     Santa Clara                                   Orzota, Inc.      US   \n",
       "20       Los Gatos                                        Netflix      US   \n",
       "21     Santa Clara                                         Citrix      US   \n",
       "22       Los Gatos                                        Netflix      US   \n",
       "23       Los Gatos                                        Netflix      US   \n",
       "24       Palo Alto                                Orbital Insight      US   \n",
       "25     Santa Clara                                   Danaher Labs      US   \n",
       "26     Santa Clara                                         Citrix      US   \n",
       "27        San Jose                                            IBM      US   \n",
       "28        San Jose                                           TiVo      US   \n",
       "29        San Jose                Bloom Consulting Services, LLC.      US   \n",
       "..             ...                                            ...     ...   \n",
       "332     Menlo Park                                        Earlens      US   \n",
       "333      Palo Alto                                 Elti Solutions      US   \n",
       "334      Palo Alto                                         DuPont      US   \n",
       "335        Fremont                                        Ardelyx      US   \n",
       "336      Palo Alto                                 Elti Solutions      US   \n",
       "337  Mountain View                                       Symantec      US   \n",
       "338      Palo Alto                                         DuPont      US   \n",
       "339      Sunnyvale                                        Cepheid      US   \n",
       "340       Stanford                            Stanford University      US   \n",
       "341       San Jose                           Stanford Health Care      US   \n",
       "342        Fremont                                        Ardelyx      US   \n",
       "343      Palo Alto                                         DuPont      US   \n",
       "344        Fremont                                        Ardelyx      US   \n",
       "345      Palo Alto                                         DuPont      US   \n",
       "346     Menlo Park                                       Exponent      US   \n",
       "347      Palo Alto                                         DuPont      US   \n",
       "348       Milpitas                                   KLA - Tencor      US   \n",
       "349       San Jose                                           Tyco      US   \n",
       "350       San Jose                                           Tyco      US   \n",
       "351      Palo Alto                        Embedded Resource Group      US   \n",
       "352      Palo Alto                     Jazz Pharmaceuticals, Inc.      US   \n",
       "353       Milpitas                                   KLA - Tencor      US   \n",
       "354      Palo Alto                                         DuPont      US   \n",
       "355      Palo Alto                                         DuPont      US   \n",
       "356      Palo Alto                                         DuPont      US   \n",
       "357      Palo Alto                                         DuPont      US   \n",
       "358       Milpitas                                   KLA - Tencor      US   \n",
       "359      Palo Alto                                          Infer      US   \n",
       "360      Palo Alto                                      HealthTap      US   \n",
       "361    Santa Clara                                      Ambarella      US   \n",
       "\n",
       "                              date  \\\n",
       "0    Sat, 19 Mar 2016 01:21:01 GMT   \n",
       "1    Fri, 18 Mar 2016 17:09:03 GMT   \n",
       "2    Mon, 21 Mar 2016 21:16:01 GMT   \n",
       "3    Thu, 24 Mar 2016 03:06:08 GMT   \n",
       "4    Wed, 16 Mar 2016 15:20:23 GMT   \n",
       "5    Sun, 20 Mar 2016 06:55:32 GMT   \n",
       "6    Thu, 03 Mar 2016 03:48:17 GMT   \n",
       "7    Mon, 07 Mar 2016 12:44:55 GMT   \n",
       "8    Wed, 16 Mar 2016 15:20:56 GMT   \n",
       "9    Wed, 16 Mar 2016 05:03:33 GMT   \n",
       "10   Tue, 08 Mar 2016 22:01:28 GMT   \n",
       "11   Sat, 19 Mar 2016 10:33:39 GMT   \n",
       "12   Thu, 24 Mar 2016 00:31:43 GMT   \n",
       "13   Wed, 23 Mar 2016 06:45:50 GMT   \n",
       "14   Tue, 15 Mar 2016 17:00:37 GMT   \n",
       "15   Fri, 25 Mar 2016 12:43:58 GMT   \n",
       "16   Tue, 22 Mar 2016 14:53:46 GMT   \n",
       "17   Thu, 17 Mar 2016 01:59:03 GMT   \n",
       "18   Thu, 24 Mar 2016 01:59:40 GMT   \n",
       "19   Wed, 23 Mar 2016 04:45:33 GMT   \n",
       "20   Wed, 16 Mar 2016 05:03:11 GMT   \n",
       "21   Sat, 05 Mar 2016 06:00:09 GMT   \n",
       "22   Tue, 15 Mar 2016 22:56:56 GMT   \n",
       "23   Wed, 16 Mar 2016 05:03:48 GMT   \n",
       "24   Thu, 17 Mar 2016 02:34:20 GMT   \n",
       "25   Thu, 24 Mar 2016 00:31:43 GMT   \n",
       "26   Sat, 05 Mar 2016 06:00:09 GMT   \n",
       "27   Fri, 18 Mar 2016 03:06:02 GMT   \n",
       "28   Sun, 20 Mar 2016 06:55:32 GMT   \n",
       "29   Mon, 14 Mar 2016 18:09:12 GMT   \n",
       "..                             ...   \n",
       "332  Wed, 23 Mar 2016 11:16:51 GMT   \n",
       "333  Thu, 03 Mar 2016 03:17:10 GMT   \n",
       "334  Sat, 05 Mar 2016 01:38:41 GMT   \n",
       "335  Tue, 08 Mar 2016 11:25:35 GMT   \n",
       "336  Thu, 03 Mar 2016 03:17:09 GMT   \n",
       "337  Fri, 18 Mar 2016 00:16:05 GMT   \n",
       "338  Sat, 05 Mar 2016 01:37:35 GMT   \n",
       "339  Tue, 01 Mar 2016 03:19:40 GMT   \n",
       "340  Sat, 26 Mar 2016 01:42:09 GMT   \n",
       "341  Thu, 17 Mar 2016 07:08:50 GMT   \n",
       "342  Tue, 08 Mar 2016 11:26:08 GMT   \n",
       "343  Sat, 05 Mar 2016 01:37:52 GMT   \n",
       "344  Tue, 08 Mar 2016 11:26:07 GMT   \n",
       "345  Sat, 05 Mar 2016 01:37:35 GMT   \n",
       "346  Wed, 02 Mar 2016 17:57:46 GMT   \n",
       "347  Sat, 05 Mar 2016 01:37:35 GMT   \n",
       "348  Sat, 19 Mar 2016 00:07:54 GMT   \n",
       "349  Tue, 08 Mar 2016 23:50:11 GMT   \n",
       "350  Tue, 08 Mar 2016 23:50:11 GMT   \n",
       "351  Wed, 02 Mar 2016 22:05:05 GMT   \n",
       "352  Tue, 22 Mar 2016 23:32:43 GMT   \n",
       "353  Sat, 19 Mar 2016 00:07:54 GMT   \n",
       "354  Sat, 05 Mar 2016 01:37:35 GMT   \n",
       "355  Sat, 05 Mar 2016 01:37:53 GMT   \n",
       "356  Sat, 05 Mar 2016 01:37:34 GMT   \n",
       "357  Sat, 05 Mar 2016 01:37:53 GMT   \n",
       "358  Thu, 10 Mar 2016 02:01:11 GMT   \n",
       "359  Tue, 01 Mar 2016 07:16:46 GMT   \n",
       "360  Thu, 03 Mar 2016 07:25:58 GMT   \n",
       "361  Wed, 02 Mar 2016 07:20:10 GMT   \n",
       "\n",
       "                                           description expired indeedApply  \\\n",
       "0                Data Scientist - 43275  Description     false       false   \n",
       "1    Must-Haves5+ years data science experienceDegr...   false        true   \n",
       "2    As our company's first data scientist, you’ll ...   false        true   \n",
       "3    Job Description  What makes the difference bet...   false       false   \n",
       "4    Data Scientist: - Candidate should have a stro...   false        true   \n",
       "5    Support both internal and external client init...   false       false   \n",
       "6    Requisition No.: 121517BR  Subsidiary: eBay Ma...   false       false   \n",
       "7    Role : FTE ( Full Time Employment)Year of expe...   false        true   \n",
       "8    - Candidate should have a strong background an...   false        true   \n",
       "9    Netflix is seeking an outgoing, curious, inter...   false       false   \n",
       "10   What client looking for?The ideal candidate ha...   false        true   \n",
       "11   T&M; Consulting Inc (A Michigan Based Company)...   false        true   \n",
       "12   -  DAN000446  About Us  Launching in 2014, Dan...   false       false   \n",
       "13   Are you passionate about solving interesting a...   false       false   \n",
       "14   MTS 1, Data ScientistJob DescriptionAt Fanatic...   false        true   \n",
       "15   This position's primary focus is to manipulate...   false        true   \n",
       "16   5+ years data science experienceDegree in phys...   false        true   \n",
       "17   Job Requirement: 1/ Gather and analyze data, i...   false        true   \n",
       "18   Our Client is looking to Direct Hire a Data Sc...   false        true   \n",
       "19   Looking for a strong data scientist to work at...   false        true   \n",
       "20   Netflix is seeking a talented and versatile da...   false       false   \n",
       "21   We believe work is not a place, but rather a t...   false       false   \n",
       "22   Netflix is revolutionizing entertainment. We d...   false       false   \n",
       "23   Netflix is revolutionizing entertainment. We d...   false       false   \n",
       "24   Data Scientist   Our mission is to turn Geospa...   false       false   \n",
       "25   -  DAN000446  About Us  Launching in 2014, Dan...   false       false   \n",
       "26   We believe work is not a place, but rather a t...   false       false   \n",
       "27   Job Description  Energy Storage Science and So...   false       false   \n",
       "28   Support both internal and external client init...   false       false   \n",
       "29   Position: Data Scientist (Modeler)Duration: Fu...   false        true   \n",
       "..                                                 ...     ...         ...   \n",
       "332  Clinical Menlo Park, CA JOB DESCRIPTION  About...   false       false   \n",
       "333  A generously funded (more than $13 mln in seed...   false        true   \n",
       "334  Here is a learning environment like no other! ...   false       false   \n",
       "335  Ardelyx? is a rapidly emerging biotech company...   false       false   \n",
       "336  A generously funded (more than $13 mln in seed...   false        true   \n",
       "337                          Symantec Website Security   false       false   \n",
       "338  Here is a learning environment like no other! ...   false       false   \n",
       "339  Start your career with us today and make a big...   false       false   \n",
       "340  As the oldest medical school in the western Un...   false       false   \n",
       "341  The Stanford Cancer Center is expanding its fa...   false       false   \n",
       "342  Department: Translational Biology Reports to: ...   false       false   \n",
       "343  Here is a learning environment like no other! ...   false       false   \n",
       "344  We are currently seeking a Principal Investiga...   false       false   \n",
       "345  Here is a learning environment like no other! ...   false       false   \n",
       "346                                          Exponent    false       false   \n",
       "347  Here is a learning environment like no other! ...   false       false   \n",
       "348  Position : Senior Research Scientist Location ...   false       false   \n",
       "349  Tyco (NYSE: TYC) is the world’s largest pure-p...   false       false   \n",
       "350  Tyco (NYSE: TYC) is the world’s largest pure-p...   false       false   \n",
       "351  UX Designer  UX design for applications dealin...   false       false   \n",
       "352  Jazz Pharmaceuticals is seeking a clinical sci...   false       false   \n",
       "353  Position : Senior Research Scientist Location ...   false       false   \n",
       "354  Here is a learning environment like no other! ...   false       false   \n",
       "355  Here is a learning environment like no other! ...   false       false   \n",
       "356  Here is a learning environment like no other! ...   false       false   \n",
       "357  Here is a learning environment like no other! ...   false       false   \n",
       "358  Job Description :Business Unit: The Film and S...   false       false   \n",
       "359  We are looking for a senior data scientist wit...   false       false   \n",
       "360  HealthTap is taking off!  As Data Scientist ea...   false       false   \n",
       "361  Microcode engineers at Ambarella are responsib...   false       false   \n",
       "\n",
       "               jobkey                                           jobtitle  \\\n",
       "0    60351a8c21c7ea69                                     Data Scientist   \n",
       "1    b96e8049255fb8bc                                     Data Scientist   \n",
       "2    c584e9cc43bcb0fa                                     Data Scientist   \n",
       "3    ae4133ed7f8423de                                     Data Scientist   \n",
       "4    4438dc8a975bda84                                    Data Scientist:   \n",
       "5    b976a589270769c2                                     Data Scientist   \n",
       "6    f87400e4ba147c37                                     Data Scientist   \n",
       "7    9ee83a44bc428657                                     Data Scientist   \n",
       "8    d36adf11e3e115ea                     Data Scientist - Sunnyvale, CA   \n",
       "9    2ad11d20dd1131bf  Senior Data Scientist - Machine Learning Research   \n",
       "10   4350d3eaca1309a3                                     Data scientist   \n",
       "11   1bcf0b3d646b66ff                                     Data Scientist   \n",
       "12   a0bc2cca3f4c4157     Data Scientist - Danaher Labs, Santa Clara, CA   \n",
       "13   b9f59065003e5882                 Data Scientist, Local Intelligence   \n",
       "14   1f90af91dcf964a5                                     Data Scientist   \n",
       "15   a1281b7096145fd1                                     Data Scientist   \n",
       "16   e90f3333dafb2742                                     Data Scientist   \n",
       "17   e4c8afe8b782e7dc                Machine Learning and Data Scientist   \n",
       "18   2c59d3de0c872cb8                                     Data Scientist   \n",
       "19   5a6793c9d9070b26            Data Scientist with Big Data background   \n",
       "20   7a1aa35ecb6794b9  Senior Data Scientist - Algorithm Experimentation   \n",
       "21   6588901dac07bbd5                                     Data Scientist   \n",
       "22   593dfe304f003ab7  Senior Data Scientist - Streaming Experimentat...   \n",
       "23   f6e7ecdc7a0ae6b1  Senior Data Scientist - Streaming Science & Al...   \n",
       "24   e5d62cd4046669e3                                     Data Scientist   \n",
       "25   a0bc2cca3f4c4157     Data Scientist - Danaher Labs, Santa Clara, CA   \n",
       "26   6588901dac07bbd5                                     Data Scientist   \n",
       "27   c6b10d54a5e7598d  Research Scientists-Energy Storage Science and...   \n",
       "28   b976a589270769c2                                     Data Scientist   \n",
       "29   3fc44bc38fa81e82                           Data Scientist (Modeler)   \n",
       "..                ...                                                ...   \n",
       "332  2710948526dcccc2                                  Hearing Scientist   \n",
       "333  532f0c302afa2e06       Senior Frontend Engineer, Inference Platform   \n",
       "334  9f302cd0cee873eb  Summer Internship: Exploring the feasibility o...   \n",
       "335  903c192565590f77                 Scientist- Pharmaceutical Analysis   \n",
       "336  2aae29e6f07f2a48  Senior Software Engineer, Inference Platform d...   \n",
       "337  6f7c0944ef37ce0b                     Director of Revenue Operations   \n",
       "338  f068b7ba3b4fa5d0  Summer Internship: Assessment of high-throughp...   \n",
       "339  3ebac3961bfa14e8                Software Quality Engineering Intern   \n",
       "340  7328caed6071e70f                    Human Resources Administrator 1   \n",
       "341  bc5009434bbf1b80  Clinical Lab Scientist Relief (Chem/Coag/Hem) ...   \n",
       "342  7fc3717d282f96bb                           Bioinformatics Scientist   \n",
       "343  a2aa53056f16e68e  Summer Internship: Assessment and evaluation o...   \n",
       "344  833b4632a743be2e       Principal Investigator - Cardiorenal Disease   \n",
       "345  7c247470cff1e08c  Summer Internship: Evaluating Protein Solubili...   \n",
       "346  f08a37748b6092fc                       Associate/Engineer/Scientist   \n",
       "347  25b8955b4fdeee63  Summer Internship: IB Regulatory Building Bloc...   \n",
       "348  a09c72c7e446ee5a  Senior Research Scientist ( C++ | Object Orien...   \n",
       "349  2cbc49400113667f  Sr. Software Engineer-Computer Vision, Tyco Te...   \n",
       "350  2cbc49400113667f  Sr. Software Engineer-Computer Vision, Tyco Te...   \n",
       "351  e405c6c4182c6253                                 UX Designer (4712)   \n",
       "352  f3ad03b1c0015e99  Clinical Scientist, Sleep Development, Clin De...   \n",
       "353  a09c72c7e446ee5a  Senior Research Scientist ( C++ | Object Orien...   \n",
       "354  e51c1ce70d27cf3d  Summer Internship: Metabolomics analysis of Ba...   \n",
       "355  d7c77cda32583af2  Summer Internship: Evaluating bioreactor syste...   \n",
       "356  63e63d09b0956010  Summer Internship: Testing Feasibility of a Ba...   \n",
       "357  31d9e016c940bb59  Summer Internship: Predicting Protein Solubili...   \n",
       "358  7e2480b2a577ec91  Sr. Software Engineer ( C++ | OO | Computation...   \n",
       "359  37d37eee0c0a3fad                                     Data Scientist   \n",
       "360  ac7f7e283bc6cc36                                     Data Scientist   \n",
       "361  dd7d8dda2f68a3be     Software Engineer - Microcode Group (Job#1188)   \n",
       "\n",
       "      latitude    longitude          origin  \\\n",
       "0    37.337914   -121.89011  san+jose%2C+ca   \n",
       "1     37.43956   -122.14286  san+jose%2C+ca   \n",
       "2     37.43956   -122.14286  san+jose%2C+ca   \n",
       "3    37.384617   -122.08242  san+jose%2C+ca   \n",
       "4     37.32143   -122.02747  san+jose%2C+ca   \n",
       "5      37.4001   -121.89531  san+jose%2C+ca   \n",
       "6    37.337914   -121.89011  san+jose%2C+ca   \n",
       "7    37.337914   -121.89011  san+jose%2C+ca   \n",
       "8    37.368134   -122.03297  san+jose%2C+ca   \n",
       "9    37.225273   -121.97253  san+jose%2C+ca   \n",
       "10   37.337914   -121.89011  san+jose%2C+ca   \n",
       "11   37.368134   -122.03297  san+jose%2C+ca   \n",
       "12    37.35165   -121.95055  san+jose%2C+ca   \n",
       "13    37.42517   -122.13624  san+jose%2C+ca   \n",
       "14   37.365383   -122.03297  san+jose%2C+ca   \n",
       "15   37.399815   -122.13571  san+jose%2C+ca   \n",
       "16    37.43956   -122.14835  san+jose%2C+ca   \n",
       "17    37.35165   -121.95055  san+jose%2C+ca   \n",
       "18    37.43956   -122.14286  san+jose%2C+ca   \n",
       "19    37.35165   -121.95055  san+jose%2C+ca   \n",
       "20   37.225273   -121.97253  san+jose%2C+ca   \n",
       "21    37.40236   -121.97912  san+jose%2C+ca   \n",
       "22   37.225273   -121.97253  san+jose%2C+ca   \n",
       "23   37.225273   -121.97253  san+jose%2C+ca   \n",
       "24   37.414837   -122.13187  san+jose%2C+ca   \n",
       "25    37.35165   -121.95055  san+jose%2C+ca   \n",
       "26    37.40236   -121.97912  san+jose%2C+ca   \n",
       "27   37.337914   -121.89011  san+jose%2C+ca   \n",
       "28     37.4001   -121.89531  san+jose%2C+ca   \n",
       "29   37.337914   -121.89011  san+jose%2C+ca   \n",
       "..         ...          ...             ...   \n",
       "332   37.48045   -122.18158  san+jose%2C+ca   \n",
       "333   37.43956   -122.14286  san+jose%2C+ca   \n",
       "334   37.43956   -122.14286  san+jose%2C+ca   \n",
       "335  37.557503  -122.064125  san+jose%2C+ca   \n",
       "336   37.43956   -122.14286  san+jose%2C+ca   \n",
       "337  37.384617   -122.08242  san+jose%2C+ca   \n",
       "338   37.43956   -122.14286  san+jose%2C+ca   \n",
       "339  37.368134   -122.03297  san+jose%2C+ca   \n",
       "340    37.4282    -122.1775  san+jose%2C+ca   \n",
       "341  37.337914   -121.89011  san+jose%2C+ca   \n",
       "342  37.557503  -122.064125  san+jose%2C+ca   \n",
       "343   37.43956   -122.14286  san+jose%2C+ca   \n",
       "344  37.557503  -122.064125  san+jose%2C+ca   \n",
       "345   37.43956   -122.14286  san+jose%2C+ca   \n",
       "346  37.481056   -122.17388  san+jose%2C+ca   \n",
       "347   37.43956   -122.14286  san+jose%2C+ca   \n",
       "348  37.436813   -121.88461  san+jose%2C+ca   \n",
       "349  37.337914   -121.89011  san+jose%2C+ca   \n",
       "350  37.337914   -121.89011  san+jose%2C+ca   \n",
       "351  37.406593   -122.15385  san+jose%2C+ca   \n",
       "352  37.406998   -122.14846  san+jose%2C+ca   \n",
       "353  37.436813   -121.88461  san+jose%2C+ca   \n",
       "354   37.43956   -122.14286  san+jose%2C+ca   \n",
       "355   37.43956   -122.14286  san+jose%2C+ca   \n",
       "356   37.43956   -122.14286  san+jose%2C+ca   \n",
       "357   37.43956   -122.14286  san+jose%2C+ca   \n",
       "358  37.436813   -121.88461  san+jose%2C+ca   \n",
       "359   37.43956   -122.14286  san+jose%2C+ca   \n",
       "360   37.43956   -122.14286  san+jose%2C+ca   \n",
       "361   37.37544   -121.99687  san+jose%2C+ca   \n",
       "\n",
       "                                               snippet  \\\n",
       "0    Advanced statistical modeling, machine learnin...   \n",
       "1    Experience coding in Python, R, or Clojure to ...   \n",
       "2    Data Scientist experience:. Coding in Python, ...   \n",
       "3    A given day could have you doing Machine Learn...   \n",
       "4    Candidate should have worked on different algo...   \n",
       "5    Working with a team of data engineers and data...   \n",
       "6    The ideal candidate is an independent, solutio...   \n",
       "7    Apply Data Science and Machine Learning to a v...   \n",
       "8    Strength in Machine Learning, Statistical Mode...   \n",
       "9    As a senior data scientist, you will:. Bring a...   \n",
       "10   Work collaboratively in a cross functional fea...   \n",
       "11   Candidate should have worked on different algo...   \n",
       "12   Danaher Labs is seeking a Data Scientist who i...   \n",
       "13   Strong analytical background, at least a BS, a...   \n",
       "14   Experience developing machine learning, NLP an...   \n",
       "15   Individuals within the Data Scientist role are...   \n",
       "16   Experience coding in Python, R, or Clojure to ...   \n",
       "17   1/ Gather and analyze data, identify key predi...   \n",
       "18   Experience coding in Python, R, or Clojure to ...   \n",
       "19   1+ years of experience in big data projects as...   \n",
       "20   Proficiency with a statistical analysis tool s...   \n",
       "21   R2283 Data Scientist (Open). Connect with inte...   \n",
       "22   4+ years relevant experience with a proven tra...   \n",
       "23   Expertise in machine learning, Natural Languag...   \n",
       "24   Along with our team of data scientists, you’ll...   \n",
       "25   Danaher Labs is seeking a Data Scientist who i...   \n",
       "26   R2283 Data Scientist (Open). Connect with inte...   \n",
       "27   Energy Storage Science and Solutions group at ...   \n",
       "28   Working with a team of data engineers and data...   \n",
       "29   Data Scientist (Modeler)*. Need someone with s...   \n",
       "..                                                 ...   \n",
       "332  The hearing scientist reports into the Directo...   \n",
       "333  Opportunity to work on a small team of ~10 ama...   \n",
       "334  DuPont Industrial Biosciences strongly believe...   \n",
       "335  Independently interpret and present data to a ...   \n",
       "336  Opportunity to work on a small team of ~10 ama...   \n",
       "337  Symantec Website SecurityDelivering Confidence...   \n",
       "338  DuPont Industrial Biosciences strongly believe...   \n",
       "339  You will collaborate with the Software Enginee...   \n",
       "340  As the oldest medical school in the western Un...   \n",
       "341  Recognized for advanced clinical care, scienti...   \n",
       "342  Scientists, advanced thinkers, and people who ...   \n",
       "343  DuPont Industrial Biosciences strongly believe...   \n",
       "344  Assist the clinical development team in provid...   \n",
       "345  DuPont Industrial Biosciences strongly believe...   \n",
       "346  This position requires some travel and will in...   \n",
       "347  DuPont Industrial Biosciences strongly believe...   \n",
       "348  Computational physics, scientific programming,...   \n",
       "349  Embedded Vision Systems – imagers, video and s...   \n",
       "350  Embedded Vision Systems – imagers, video and s...   \n",
       "351  Research scientists, UI and 3D artists, intera...   \n",
       "352  Read and interpret scientific and medical lite...   \n",
       "353  Computational physics, scientific programming,...   \n",
       "354  DuPont Industrial Biosciences strongly believe...   \n",
       "355  DuPont Industrial Biosciences strongly believe...   \n",
       "356  DuPont Industrial Biosciences strongly believe...   \n",
       "357  DuPont Industrial Biosciences strongly believe...   \n",
       "358  Computational physics, scientific programming,...   \n",
       "359  We are looking for a senior data scientist wit...   \n",
       "360  Solid grounding in applied mathematics and sta...   \n",
       "361  Develop a deep understanding of Ambarellaâs ...   \n",
       "\n",
       "                     source sponsored state  \n",
       "0                     Adobe     false    CA  \n",
       "1                    Indeed     false    CA  \n",
       "2                    Indeed     false    CA  \n",
       "3               UserTesting     false    CA  \n",
       "4                    Indeed     false    CA  \n",
       "5                      TiVo     false    CA  \n",
       "6                      Ebay     false    CA  \n",
       "7                    Indeed     false    CA  \n",
       "8                    Indeed     false    CA  \n",
       "9                   Netflix     false    CA  \n",
       "10                   Indeed     false    CA  \n",
       "11                   Indeed     false    CA  \n",
       "12                  Danaher     false    CA  \n",
       "13                  Groupon     false    CA  \n",
       "14                   Indeed     false    CA  \n",
       "15                   Indeed     false    CA  \n",
       "16                   Indeed     false    CA  \n",
       "17                   Indeed     false    CA  \n",
       "18                   Indeed     false    CA  \n",
       "19                   Indeed     false    CA  \n",
       "20                  Netflix     false    CA  \n",
       "21     Citrix Systems, Inc.     false    CA  \n",
       "22                  Netflix     false    CA  \n",
       "23                  Netflix     false    CA  \n",
       "24          Orbital Insight     false    CA  \n",
       "25                  Danaher     false    CA  \n",
       "26     Citrix Systems, Inc.     false    CA  \n",
       "27                      IBM     false    CA  \n",
       "28                     TiVo     false    CA  \n",
       "29                   Indeed     false    CA  \n",
       "..                      ...       ...   ...  \n",
       "332             StartUpHire     false    CA  \n",
       "333          Elti Solutions     false    CA  \n",
       "334                  DuPont     false    CA  \n",
       "335             StartUpHire     false    CA  \n",
       "336          Elti Solutions     false    CA  \n",
       "337                Symantec     false    CA  \n",
       "338                  DuPont     false    CA  \n",
       "339                 Cepheid     false    CA  \n",
       "340     Stanford University     false    CA  \n",
       "341  HEALTHeCAREERS Network     false    CA  \n",
       "342             StartUpHire     false    CA  \n",
       "343                  DuPont     false    CA  \n",
       "344             StartUpHire     false    CA  \n",
       "345                  DuPont     false    CA  \n",
       "346                Exponent     false    CA  \n",
       "347                  DuPont     false    CA  \n",
       "348                 Monster     false    CA  \n",
       "349                    Tyco     false    CA  \n",
       "350                    Tyco     false    CA  \n",
       "351                 Monster     false    CA  \n",
       "352         DeviceSpace.com     false    CA  \n",
       "353                 Monster     false    CA  \n",
       "354                  DuPont     false    CA  \n",
       "355                  DuPont     false    CA  \n",
       "356                  DuPont     false    CA  \n",
       "357                  DuPont     false    CA  \n",
       "358                 Monster     false    CA  \n",
       "359             VentureLoop     false    CA  \n",
       "360             VentureLoop     false    CA  \n",
       "361             VentureLoop     false    CA  \n",
       "\n",
       "[362 rows x 16 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>expired</th>\n",
       "      <th>indeedApply</th>\n",
       "      <th>jobkey</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>origin</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>IBM</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 04:06:25 GMT</td>\n",
       "      <td>Job Description  The Medical Sieve Group in Co...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>f247f5b867a461de</td>\n",
       "      <td>Data Entry Software Engineer</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>The Medical Sieve Group in Cognitive Computing...</td>\n",
       "      <td>IBM</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Pull Skill Technologies Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 01 Mar 2016 15:19:46 GMT</td>\n",
       "      <td>Position : Data Scientist – ModellerLocation :...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1f2583f9877e177f</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Provide technical expertise in statistical ana...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain View</td>\n",
       "      <td>Intuit</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 04 Mar 2016 05:20:37 GMT</td>\n",
       "      <td>Description Intuit QuickBooks is on a mission ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>702e092b96f66a52</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.392857</td>\n",
       "      <td>-122.071430</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>SAS, R, SQL, S-Plus, etc.). Quickly understand...</td>\n",
       "      <td>Intuit</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 02 Mar 2016 21:21:24 GMT</td>\n",
       "      <td>(Menlo Park, CA) Careers at Oculus A Facebook ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>200a1bff8841c9b1</td>\n",
       "      <td>Data Scientist, Analytics (Oculus)</td>\n",
       "      <td>37.453297</td>\n",
       "      <td>-122.181320</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Data Scientist, Analytics (Oculus) (Menlo Park...</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cupertino</td>\n",
       "      <td>PullSkill Technologies Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 04 Mar 2016 16:04:33 GMT</td>\n",
       "      <td>Data Scientist with PythonLocation: Cupertino ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ada491bfde6f646b</td>\n",
       "      <td>Data Scientist with Python</td>\n",
       "      <td>37.321430</td>\n",
       "      <td>-122.027470</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Data Scientist with Python*. Requesting a Pyth...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>EBay</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 03:48:17 GMT</td>\n",
       "      <td>Requisition No.: 121517BR  Subsidiary: eBay Ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>f87400e4ba147c37</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>The ideal candidate is an independent, solutio...</td>\n",
       "      <td>Ebay</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Paypal</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 08:36:40 GMT</td>\n",
       "      <td>Requisition No.: 29374BR  Subsidiary: PayPal  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4c1a428bfb229965</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Seeks Data Scientist in San Jose, CA:. Collabo...</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>EBay</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 04 Mar 2016 09:52:37 GMT</td>\n",
       "      <td>Requisition No.: 119481BR  Subsidiary: eBay Ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>198e733636a1b2dc</td>\n",
       "      <td>Senior Data Scientist/Applied Researcher</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Well versed in areas such as applied statistic...</td>\n",
       "      <td>Ebay</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Apidel Technologies</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 21:04:00 GMT</td>\n",
       "      <td>Position: Data Scientist / Big Data Engineer –...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6be0da3a4e19ef4a</td>\n",
       "      <td>Data Scientist / Big Data Engineer – Advance A...</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Data Scientist / Big Data Engineer – Advance A...</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mountain View</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 04 Mar 2016 06:36:20 GMT</td>\n",
       "      <td>Discovering the perfect course is the first an...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>369b442fc8485c3f</td>\n",
       "      <td>Data Scientist, Search and Discovery</td>\n",
       "      <td>37.387398</td>\n",
       "      <td>-122.061120</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>We're looking for a talented, independent data...</td>\n",
       "      <td>Coursera</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>SAP</td>\n",
       "      <td>US</td>\n",
       "      <td>Thu, 03 Mar 2016 20:38:58 GMT</td>\n",
       "      <td>Requisition ID: 105756 Work Area: Software-Des...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>58a0bbf451c902d5</td>\n",
       "      <td>Developer/Data Scientist Job</td>\n",
       "      <td>37.439560</td>\n",
       "      <td>-122.142860</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Familiar with one or more machine learning or ...</td>\n",
       "      <td>SAP</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 26 Feb 2016 23:59:20 GMT</td>\n",
       "      <td>Additional Location(s) or Information: Job Cat...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>aaffe9d79660fb57</td>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Machine learning, recommendation systems, patt...</td>\n",
       "      <td>Cisco Systems</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mountain View</td>\n",
       "      <td>Retail Solutions</td>\n",
       "      <td>US</td>\n",
       "      <td>Sat, 27 Feb 2016 10:04:02 GMT</td>\n",
       "      <td>ABOUT RETAIL SOLUTIONS, INC.: Retail Solutions...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a02596050b00b6c4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.387680</td>\n",
       "      <td>-122.055260</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Familiar with R programming, can use R to crea...</td>\n",
       "      <td>Bessemer Venture Partners</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Ariosa Diagnostics</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 24 Feb 2016 03:19:18 GMT</td>\n",
       "      <td>The Bioinformatics, Data Analysis and Statisti...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>326f0aed8fb7c88b</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Design data management infrastructure to clean...</td>\n",
       "      <td>Ariosa Diagnostics</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fremont</td>\n",
       "      <td>Tesla Motors</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 04 Mar 2016 19:23:06 GMT</td>\n",
       "      <td>The Role  Play a central role in designing and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12a0be24d14b0ff6</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>37.496270</td>\n",
       "      <td>-121.948230</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Work with Business Analysts, Application Devel...</td>\n",
       "      <td>Tesla Motors</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Paypal</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 02 Mar 2016 02:32:32 GMT</td>\n",
       "      <td>Requisition No.: 29268BR  Subsidiary: PayPal  ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>beee19e63c9a328d</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>The team is comprised of business analysts, st...</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mountain View</td>\n",
       "      <td>Symantec</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 12 Feb 2016 20:52:09 GMT</td>\n",
       "      <td>As a leading Fortune 500 Technology &amp; Security...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>f93df3eed5d5de58</td>\n",
       "      <td>Principal Data Scientist, Machine Learning - M...</td>\n",
       "      <td>37.384617</td>\n",
       "      <td>-122.082420</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>ResponsibilitiesHelp our efforts to improve th...</td>\n",
       "      <td>Symantec</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Chegg</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 12 Feb 2016 01:54:29 GMT</td>\n",
       "      <td>Your goal – to improve the education process a...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15113f6745641567</td>\n",
       "      <td>Staff Data Scientist - Machine Learning</td>\n",
       "      <td>37.388016</td>\n",
       "      <td>-121.973015</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>The Staff Data Scientist focusing on Machine L...</td>\n",
       "      <td>Chegg</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>Appnomic Systems Pvt. Ltd</td>\n",
       "      <td>US</td>\n",
       "      <td>Sun, 28 Feb 2016 07:28:12 GMT</td>\n",
       "      <td>Job Title : Data Scientist  Location : Sunnyva...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4908f34436ed9083</td>\n",
       "      <td>USA - Data Scientist</td>\n",
       "      <td>37.368134</td>\n",
       "      <td>-122.032970</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>We’re looking for a data scientist to help us ...</td>\n",
       "      <td>Appnomic Systems Pvt. Ltd</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>VMware</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 02 Mar 2016 13:12:41 GMT</td>\n",
       "      <td>Posting Title Project Admin Mgr - Data Analyst...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>59c438f4eaa88d7c</td>\n",
       "      <td>Project Admin Mgr - Data Analyst</td>\n",
       "      <td>37.398020</td>\n",
       "      <td>-122.142586</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Posting Title Project Admin Mgr - Data Analyst...</td>\n",
       "      <td>VMware</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>InvenSense</td>\n",
       "      <td>US</td>\n",
       "      <td>Wed, 24 Feb 2016 08:30:56 GMT</td>\n",
       "      <td>Job Description: Leverage machine learning tec...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>dd1f88f9058159cc</td>\n",
       "      <td>Data Scientist - Principal</td>\n",
       "      <td>37.369290</td>\n",
       "      <td>-121.920235</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>8+ years in the field of data science, data di...</td>\n",
       "      <td>InvenSense</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Intel</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 26 Feb 2016 05:18:42 GMT</td>\n",
       "      <td>Job Description  Intel Labs is seeking an expe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3a2d42b923ce04d2</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>37.346153</td>\n",
       "      <td>-121.978020</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Visual data processing. You are expected to ma...</td>\n",
       "      <td>Intel</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>EBay</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 26 Feb 2016 03:29:32 GMT</td>\n",
       "      <td>Requisition No.: 121376BR  Business Title: Eng...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>f2035f327993fc57</td>\n",
       "      <td>Engineer, Structured Data R&amp;D</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Machine Learning, Deep Learning. Regularly col...</td>\n",
       "      <td>Ebay</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>IBM</td>\n",
       "      <td>US</td>\n",
       "      <td>Tue, 01 Mar 2016 05:10:43 GMT</td>\n",
       "      <td>Job Description  The world continues to get “s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70bf83909abc7699</td>\n",
       "      <td>Post Doctorate Research Scientist - Smarter Pl...</td>\n",
       "      <td>37.337914</td>\n",
       "      <td>-121.890110</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>In this regard, we are seeking research scient...</td>\n",
       "      <td>IBM</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Kforce</td>\n",
       "      <td>US</td>\n",
       "      <td>Fri, 26 Feb 2016 23:47:20 GMT</td>\n",
       "      <td>RESPONSIBILITIES: Kforce has a client that is ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>292c049b952a4fcf</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>37.351650</td>\n",
       "      <td>-121.956050</td>\n",
       "      <td>san+jose%2C+ca</td>\n",
       "      <td>Creating Algorithms for data detection. Strong...</td>\n",
       "      <td>Kforce</td>\n",
       "      <td>False</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city                      company country  \\\n",
       "0        San Jose                          IBM      US   \n",
       "1        San Jose  Pull Skill Technologies Inc      US   \n",
       "2   Mountain View                       Intuit      US   \n",
       "3      Menlo Park                     Facebook      US   \n",
       "4       Cupertino   PullSkill Technologies Inc      US   \n",
       "5        San Jose                         EBay      US   \n",
       "6        San Jose                       Paypal      US   \n",
       "7        San Jose                         EBay      US   \n",
       "8        San Jose          Apidel Technologies      US   \n",
       "9   Mountain View                     Coursera      US   \n",
       "10      Palo Alto                          SAP      US   \n",
       "11       San Jose          Cisco Systems, Inc.      US   \n",
       "12  Mountain View             Retail Solutions      US   \n",
       "13       San Jose           Ariosa Diagnostics      US   \n",
       "14        Fremont                 Tesla Motors      US   \n",
       "15       San Jose                       Paypal      US   \n",
       "16  Mountain View                     Symantec      US   \n",
       "17    Santa Clara                        Chegg      US   \n",
       "18      Sunnyvale    Appnomic Systems Pvt. Ltd      US   \n",
       "19      Palo Alto                       VMware      US   \n",
       "20       San Jose                   InvenSense      US   \n",
       "21    Santa Clara                        Intel      US   \n",
       "22       San Jose                         EBay      US   \n",
       "23       San Jose                          IBM      US   \n",
       "24    Santa Clara                       Kforce      US   \n",
       "\n",
       "                             date  \\\n",
       "0   Thu, 03 Mar 2016 04:06:25 GMT   \n",
       "1   Tue, 01 Mar 2016 15:19:46 GMT   \n",
       "2   Fri, 04 Mar 2016 05:20:37 GMT   \n",
       "3   Wed, 02 Mar 2016 21:21:24 GMT   \n",
       "4   Fri, 04 Mar 2016 16:04:33 GMT   \n",
       "5   Thu, 03 Mar 2016 03:48:17 GMT   \n",
       "6   Thu, 03 Mar 2016 08:36:40 GMT   \n",
       "7   Fri, 04 Mar 2016 09:52:37 GMT   \n",
       "8   Thu, 03 Mar 2016 21:04:00 GMT   \n",
       "9   Fri, 04 Mar 2016 06:36:20 GMT   \n",
       "10  Thu, 03 Mar 2016 20:38:58 GMT   \n",
       "11  Fri, 26 Feb 2016 23:59:20 GMT   \n",
       "12  Sat, 27 Feb 2016 10:04:02 GMT   \n",
       "13  Wed, 24 Feb 2016 03:19:18 GMT   \n",
       "14  Fri, 04 Mar 2016 19:23:06 GMT   \n",
       "15  Wed, 02 Mar 2016 02:32:32 GMT   \n",
       "16  Fri, 12 Feb 2016 20:52:09 GMT   \n",
       "17  Fri, 12 Feb 2016 01:54:29 GMT   \n",
       "18  Sun, 28 Feb 2016 07:28:12 GMT   \n",
       "19  Wed, 02 Mar 2016 13:12:41 GMT   \n",
       "20  Wed, 24 Feb 2016 08:30:56 GMT   \n",
       "21  Fri, 26 Feb 2016 05:18:42 GMT   \n",
       "22  Fri, 26 Feb 2016 03:29:32 GMT   \n",
       "23  Tue, 01 Mar 2016 05:10:43 GMT   \n",
       "24  Fri, 26 Feb 2016 23:47:20 GMT   \n",
       "\n",
       "                                          description expired indeedApply  \\\n",
       "0   Job Description  The Medical Sieve Group in Co...   False       False   \n",
       "1   Position : Data Scientist – ModellerLocation :...   False        True   \n",
       "2   Description Intuit QuickBooks is on a mission ...   False       False   \n",
       "3   (Menlo Park, CA) Careers at Oculus A Facebook ...   False       False   \n",
       "4   Data Scientist with PythonLocation: Cupertino ...   False        True   \n",
       "5   Requisition No.: 121517BR  Subsidiary: eBay Ma...   False       False   \n",
       "6   Requisition No.: 29374BR  Subsidiary: PayPal  ...   False       False   \n",
       "7   Requisition No.: 119481BR  Subsidiary: eBay Ma...   False       False   \n",
       "8   Position: Data Scientist / Big Data Engineer –...   False        True   \n",
       "9   Discovering the perfect course is the first an...   False       False   \n",
       "10  Requisition ID: 105756 Work Area: Software-Des...   False       False   \n",
       "11  Additional Location(s) or Information: Job Cat...   False       False   \n",
       "12  ABOUT RETAIL SOLUTIONS, INC.: Retail Solutions...   False       False   \n",
       "13  The Bioinformatics, Data Analysis and Statisti...   False       False   \n",
       "14  The Role  Play a central role in designing and...   False       False   \n",
       "15  Requisition No.: 29268BR  Subsidiary: PayPal  ...   False       False   \n",
       "16  As a leading Fortune 500 Technology & Security...   False       False   \n",
       "17  Your goal – to improve the education process a...   False       False   \n",
       "18  Job Title : Data Scientist  Location : Sunnyva...   False       False   \n",
       "19  Posting Title Project Admin Mgr - Data Analyst...   False       False   \n",
       "20  Job Description: Leverage machine learning tec...   False       False   \n",
       "21  Job Description  Intel Labs is seeking an expe...   False       False   \n",
       "22  Requisition No.: 121376BR  Business Title: Eng...   False       False   \n",
       "23  Job Description  The world continues to get “s...   False       False   \n",
       "24  RESPONSIBILITIES: Kforce has a client that is ...   False       False   \n",
       "\n",
       "              jobkey                                           jobtitle  \\\n",
       "0   f247f5b867a461de                       Data Entry Software Engineer   \n",
       "1   1f2583f9877e177f                                     Data Scientist   \n",
       "2   702e092b96f66a52                                     Data Scientist   \n",
       "3   200a1bff8841c9b1                 Data Scientist, Analytics (Oculus)   \n",
       "4   ada491bfde6f646b                         Data Scientist with Python   \n",
       "5   f87400e4ba147c37                                     Data Scientist   \n",
       "6   4c1a428bfb229965                                     Data Scientist   \n",
       "7   198e733636a1b2dc           Senior Data Scientist/Applied Researcher   \n",
       "8   6be0da3a4e19ef4a  Data Scientist / Big Data Engineer – Advance A...   \n",
       "9   369b442fc8485c3f               Data Scientist, Search and Discovery   \n",
       "10  58a0bbf451c902d5                       Developer/Data Scientist Job   \n",
       "11  aaffe9d79660fb57                             Data Scientist/Analyst   \n",
       "12  a02596050b00b6c4                                     Data Scientist   \n",
       "13  326f0aed8fb7c88b                                     Data Scientist   \n",
       "14  12a0be24d14b0ff6                                      Data Engineer   \n",
       "15  beee19e63c9a328d                                 Sr. Data Scientist   \n",
       "16  f93df3eed5d5de58  Principal Data Scientist, Machine Learning - M...   \n",
       "17  15113f6745641567            Staff Data Scientist - Machine Learning   \n",
       "18  4908f34436ed9083                               USA - Data Scientist   \n",
       "19  59c438f4eaa88d7c                   Project Admin Mgr - Data Analyst   \n",
       "20  dd1f88f9058159cc                         Data Scientist - Principal   \n",
       "21  3a2d42b923ce04d2                                 Research Scientist   \n",
       "22  f2035f327993fc57                      Engineer, Structured Data R&D   \n",
       "23  70bf83909abc7699  Post Doctorate Research Scientist - Smarter Pl...   \n",
       "24  292c049b952a4fcf                                     Data Scientist   \n",
       "\n",
       "     latitude   longitude          origin  \\\n",
       "0   37.337914 -121.890110  san+jose%2C+ca   \n",
       "1   37.337914 -121.890110  san+jose%2C+ca   \n",
       "2   37.392857 -122.071430  san+jose%2C+ca   \n",
       "3   37.453297 -122.181320  san+jose%2C+ca   \n",
       "4   37.321430 -122.027470  san+jose%2C+ca   \n",
       "5   37.337914 -121.890110  san+jose%2C+ca   \n",
       "6   37.337914 -121.890110  san+jose%2C+ca   \n",
       "7   37.337914 -121.890110  san+jose%2C+ca   \n",
       "8   37.337914 -121.890110  san+jose%2C+ca   \n",
       "9   37.387398 -122.061120  san+jose%2C+ca   \n",
       "10  37.439560 -122.142860  san+jose%2C+ca   \n",
       "11  37.337914 -121.890110  san+jose%2C+ca   \n",
       "12  37.387680 -122.055260  san+jose%2C+ca   \n",
       "13  37.337914 -121.890110  san+jose%2C+ca   \n",
       "14  37.496270 -121.948230  san+jose%2C+ca   \n",
       "15  37.337914 -121.890110  san+jose%2C+ca   \n",
       "16  37.384617 -122.082420  san+jose%2C+ca   \n",
       "17  37.388016 -121.973015  san+jose%2C+ca   \n",
       "18  37.368134 -122.032970  san+jose%2C+ca   \n",
       "19  37.398020 -122.142586  san+jose%2C+ca   \n",
       "20  37.369290 -121.920235  san+jose%2C+ca   \n",
       "21  37.346153 -121.978020  san+jose%2C+ca   \n",
       "22  37.337914 -121.890110  san+jose%2C+ca   \n",
       "23  37.337914 -121.890110  san+jose%2C+ca   \n",
       "24  37.351650 -121.956050  san+jose%2C+ca   \n",
       "\n",
       "                                              snippet  \\\n",
       "0   The Medical Sieve Group in Cognitive Computing...   \n",
       "1   Provide technical expertise in statistical ana...   \n",
       "2   SAS, R, SQL, S-Plus, etc.). Quickly understand...   \n",
       "3   Data Scientist, Analytics (Oculus) (Menlo Park...   \n",
       "4   Data Scientist with Python*. Requesting a Pyth...   \n",
       "5   The ideal candidate is an independent, solutio...   \n",
       "6   Seeks Data Scientist in San Jose, CA:. Collabo...   \n",
       "7   Well versed in areas such as applied statistic...   \n",
       "8   Data Scientist / Big Data Engineer – Advance A...   \n",
       "9   We're looking for a talented, independent data...   \n",
       "10  Familiar with one or more machine learning or ...   \n",
       "11  Machine learning, recommendation systems, patt...   \n",
       "12  Familiar with R programming, can use R to crea...   \n",
       "13  Design data management infrastructure to clean...   \n",
       "14  Work with Business Analysts, Application Devel...   \n",
       "15  The team is comprised of business analysts, st...   \n",
       "16  ResponsibilitiesHelp our efforts to improve th...   \n",
       "17  The Staff Data Scientist focusing on Machine L...   \n",
       "18  We’re looking for a data scientist to help us ...   \n",
       "19  Posting Title Project Admin Mgr - Data Analyst...   \n",
       "20  8+ years in the field of data science, data di...   \n",
       "21  Visual data processing. You are expected to ma...   \n",
       "22  Machine Learning, Deep Learning. Regularly col...   \n",
       "23  In this regard, we are seeking research scient...   \n",
       "24  Creating Algorithms for data detection. Strong...   \n",
       "\n",
       "                       source sponsored state  \n",
       "0                         IBM     False    CA  \n",
       "1                      Indeed     False    CA  \n",
       "2                      Intuit     False    CA  \n",
       "3                    Facebook     False    CA  \n",
       "4                      Indeed     False    CA  \n",
       "5                        Ebay     False    CA  \n",
       "6                      PayPal     False    CA  \n",
       "7                        Ebay     False    CA  \n",
       "8                      Indeed     False    CA  \n",
       "9                    Coursera     False    CA  \n",
       "10                        SAP     False    CA  \n",
       "11              Cisco Systems     False    CA  \n",
       "12  Bessemer Venture Partners     False    CA  \n",
       "13         Ariosa Diagnostics     False    CA  \n",
       "14               Tesla Motors     False    CA  \n",
       "15                     PayPal     False    CA  \n",
       "16                   Symantec     False    CA  \n",
       "17                      Chegg     False    CA  \n",
       "18  Appnomic Systems Pvt. Ltd     False    CA  \n",
       "19                     VMware     False    CA  \n",
       "20                 InvenSense     False    CA  \n",
       "21                      Intel     False    CA  \n",
       "22                       Ebay     False    CA  \n",
       "23                        IBM     False    CA  \n",
       "24                     Kforce     False    CA  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get a search term\n",
    "#if you see a search term in a description, return true.\n",
    "#if you don't, return false.\n",
    "#For that search term, add a column to the pandas data frame.\n",
    "#The title of that column is the search term\n",
    "#The value is true or false!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['position',\n",
       " ':',\n",
       " 'data',\n",
       " 'scientist',\n",
       " '–',\n",
       " 'modellerlocation',\n",
       " ':',\n",
       " 'san',\n",
       " 'jose',\n",
       " ',',\n",
       " 'caduration',\n",
       " ':',\n",
       " 'fulltime',\n",
       " '/',\n",
       " 'permanent1',\n",
       " ')',\n",
       " 'data',\n",
       " 'scientist',\n",
       " '–*',\n",
       " '*modellerfluent',\n",
       " 'in',\n",
       " 'python.hadoop',\n",
       " ',',\n",
       " 'java',\n",
       " ',',\n",
       " 'python',\n",
       " ',',\n",
       " 'hive/pig',\n",
       " 'for',\n",
       " 'extracting',\n",
       " 'and',\n",
       " 'parsing',\n",
       " 'data.visualization',\n",
       " 'skills',\n",
       " '-',\n",
       " 'javascript',\n",
       " '(',\n",
       " 'especially',\n",
       " 'd3.js',\n",
       " ')',\n",
       " '.the',\n",
       " 'person',\n",
       " 'should',\n",
       " 'have',\n",
       " 'some',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'stats',\n",
       " '&',\n",
       " 'machine',\n",
       " 'learning.position',\n",
       " ':',\n",
       " 'data',\n",
       " 'scientist',\n",
       " '–',\n",
       " 'software',\n",
       " 'engineer',\n",
       " '(',\n",
       " 'swe',\n",
       " ')',\n",
       " 'modellerlocation',\n",
       " ':',\n",
       " 'san',\n",
       " 'jose',\n",
       " ',',\n",
       " 'caduration',\n",
       " ':',\n",
       " 'fulltime',\n",
       " '/',\n",
       " 'permanent2',\n",
       " ')',\n",
       " 'data',\n",
       " 'scientist',\n",
       " '–',\n",
       " 'software',\n",
       " 'engineer',\n",
       " '(',\n",
       " 'swe',\n",
       " ')',\n",
       " 'statistical/data',\n",
       " 'modeling/data',\n",
       " 'mining',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learningproficiency',\n",
       " 'in',\n",
       " 'sql',\n",
       " 'and',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'petabytes',\n",
       " 'of',\n",
       " 'log',\n",
       " 'files',\n",
       " 'and',\n",
       " 'other',\n",
       " 'unstructured',\n",
       " 'data.python/r/java/scala/c/c++',\n",
       " ',',\n",
       " 'spark',\n",
       " ',',\n",
       " 'hadoop',\n",
       " ',',\n",
       " 'hive',\n",
       " ',',\n",
       " 'hbase',\n",
       " ',',\n",
       " 'text/nlp',\n",
       " ',',\n",
       " 'gpuspeople',\n",
       " 'with',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'backgroundeducation',\n",
       " ':',\n",
       " 'ms',\n",
       " '/',\n",
       " 'phd',\n",
       " 'in',\n",
       " 'engineering',\n",
       " ',',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'operations',\n",
       " 'research',\n",
       " 'etcjob',\n",
       " 'responsibilities',\n",
       " ':',\n",
       " 'develop',\n",
       " 'predictive',\n",
       " 'models',\n",
       " 'and',\n",
       " 'provide',\n",
       " 'statistical',\n",
       " 'insights',\n",
       " 'using',\n",
       " 'big',\n",
       " 'data',\n",
       " 'tools',\n",
       " 'and',\n",
       " 'machinelearning.analyze',\n",
       " 'petabytes',\n",
       " 'of',\n",
       " 'real-world',\n",
       " 'performance',\n",
       " 'data',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'trends.transform',\n",
       " 'these',\n",
       " 'insights',\n",
       " 'into',\n",
       " 'actionable',\n",
       " 'reports',\n",
       " ',',\n",
       " 'targeting',\n",
       " 'algorithms',\n",
       " ',',\n",
       " 'and',\n",
       " 'personalizationfactors.provide',\n",
       " 'technical',\n",
       " 'expertise',\n",
       " 'in',\n",
       " 'statistical',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'data',\n",
       " 'mining',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'nlp',\n",
       " ',',\n",
       " 'andinformation',\n",
       " 'retrieval.design',\n",
       " 'and',\n",
       " 'deliver',\n",
       " 'scalable',\n",
       " 'software',\n",
       " 'applications',\n",
       " 'in',\n",
       " 'hadoop',\n",
       " 'and',\n",
       " 'in',\n",
       " 'real-time',\n",
       " 'platforms.estimate',\n",
       " 'engineering',\n",
       " 'effort',\n",
       " ',',\n",
       " 'plan',\n",
       " 'implementations',\n",
       " ',',\n",
       " 'and',\n",
       " 'roll',\n",
       " 'out',\n",
       " 'applications',\n",
       " 'with',\n",
       " 'cross-functionalimpact.work',\n",
       " 'jointly',\n",
       " 'with',\n",
       " 'other',\n",
       " 'team',\n",
       " 'members',\n",
       " 'to',\n",
       " 'deliver',\n",
       " 'complex',\n",
       " 'applications.conceptualizing',\n",
       " ',',\n",
       " 'coding',\n",
       " ',',\n",
       " 'deploying',\n",
       " ',',\n",
       " 'and',\n",
       " 'iterating',\n",
       " 'on',\n",
       " 'next',\n",
       " 'generation',\n",
       " 'prototypes.knowledge',\n",
       " ',',\n",
       " 'skills',\n",
       " 'and',\n",
       " 'experience',\n",
       " ':',\n",
       " 'strong',\n",
       " 'statistical/data',\n",
       " 'modeling/data',\n",
       " 'mining',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'expertise.excellent',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'fundamentals',\n",
       " ',',\n",
       " 'data',\n",
       " 'structures',\n",
       " ',',\n",
       " 'and',\n",
       " 'algorithms.successful',\n",
       " 'research',\n",
       " 'track',\n",
       " 'record',\n",
       " ',',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'applied',\n",
       " 'machine',\n",
       " 'learning',\n",
       " ',',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " 'orstatistical',\n",
       " 'modeling',\n",
       " '.',\n",
       " '(',\n",
       " 'optional',\n",
       " ')',\n",
       " 'familiarity',\n",
       " 'with',\n",
       " 'predictive',\n",
       " 'models/search/recommendation/classification',\n",
       " 'applications',\n",
       " 'anddomains',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'plus.proficiency',\n",
       " 'in',\n",
       " 'sql',\n",
       " 'and',\n",
       " 'dealing',\n",
       " 'with',\n",
       " 'petabytes',\n",
       " 'of',\n",
       " 'log',\n",
       " 'files',\n",
       " 'and',\n",
       " 'other',\n",
       " 'unstructured',\n",
       " 'data.experience',\n",
       " 'in',\n",
       " 'python/r/java/scala.experience',\n",
       " 'in',\n",
       " 'hadoop',\n",
       " ',',\n",
       " 'hive',\n",
       " ',',\n",
       " 'hbase',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'plus.solid',\n",
       " 'verbal',\n",
       " 'and',\n",
       " 'written',\n",
       " 'communication',\n",
       " 'skills.regardssyed2019-497-1010',\n",
       " 'x101job',\n",
       " 'type',\n",
       " ':',\n",
       " 'full-timesalary',\n",
       " ':',\n",
       " '$',\n",
       " '115,000.00',\n",
       " '/yearrequired',\n",
       " 'experience',\n",
       " ':',\n",
       " 'data',\n",
       " 'scientist',\n",
       " ':',\n",
       " '2',\n",
       " 'yearsrequired',\n",
       " 'education',\n",
       " ':',\n",
       " 'doctorate']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mytext = nltk.word_tokenize('This is my sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'my', 'sentence']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 1867, in run\n",
      "    for msg in self.data_server.incr_download(self.items):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 529, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 572, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 543, in incr_download\n",
      "    for msg in self.incr_download(info.children, download_dir, force):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 529, in incr_download\n",
      "    for msg in self._download_list(info_or_id, download_dir, force):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 572, in _download_list\n",
      "    for msg in self.incr_download(item, download_dir, force):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 549, in incr_download\n",
      "    for msg in self._download_package(info, download_dir, force):\n",
      "  File \"C:\\Users\\Vivek\\Anaconda3\\lib\\site-packages\\nltk\\downloader.py\", line 600, in _download_package\n",
      "    os.remove(filepath)\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\Vivek\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\panlex_lite.zip'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first = df.description[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Description Intuit QuickBooks is on a mission to transform small business lending through its QuickBooks Financing Platform. Powerful analytics and a sophisticated understanding of our customers is at the heart of our business. We are looking for a talented data scientist to join our team and help build financing solutions that delight our SMB customers. If you are excited about joining a highly ambitious and talented startup team, then keep reading!  Responsibilities: Possess a wide-latitude in determining objectives and approaches to solution development on mission critical assignments  Go beyond established analytical thinking and problem-solving by applying creativity to unconventional concepts and out-of-the-box solutions  Quickly understand patterns within large quantity of data and to reference key characteristics using visualization techniques  Collaborate with infrastructure architects in assessing and addressing the requirements for more automated, streamlined systems and for the data governance required for agile and responsive data manipulation  Build and refine a predictive model around when small businesses are most likely to need financing  Inform business decisions by building a comprehensive view of our customers by combining relevant data and signals from multiple sources  Make recommendations to enhance marketing strategy by deeply understanding the performance of every channel  Partner directly with the product development team on product instrumentation, product flow and data capture  Inform product strategy by designing A/B tests and analyzing customer behavior on our platform  Build dashboards to support day to day business decisions  Work closely with product, marketing, legal, compliance, capital markets and our current lending partners Qualifications  Proven leadership experience in the domain of Data Science  MS in Engineering Mathematics, Statistics, Theoretical/Computational Physics, or related field  Solid knowledge of statistical techniques is required  Hands-on programming experience with one or more of the following: Java, Python, R, or related languages  1-3+ years’ experience manipulating large datasets and using databases (e.g. SAS, R, SQL, S-Plus, etc.)  1-3+ years’ experience with a general-purpose programming language (e.g. C, Java, Python, etc.)  Familiarity with basic principles of distributed computing and/or distributed databases (Hadoop, NoSQL, etc.)  Demonstrable ability to quickly understand new concepts---all the way down to the theorems—and to come out with original solutions to mathematical issues  Strong interpersonal and communication skills in order to effectively contribute to technical teams and make presentations to a variety of technical and business personnel  Demonstrable skills in creative-problem-solving of complex and advanced technical subject matter  Strongly Preferred: PhD in Engineering Mathematics, Statistics, Theoretical/Computational Physics, or related field  Proven experience with Machine Learning techniques, especially on large scale datasets  Proven experience with Hadoop and related programming environments (Hive,Pig,etc)  Imagine a career where your creative inspiration can fuel BIG innovation. Year-over-year, Intuit has been recognized as a best employer and is consistently ranked on Fortune's “100 Best Companies To Work For” and Fortune World’s “Most Admired Software Companies” lists. Immerse yourself in our award winning culture while creating breakthrough solutions that simplify the lives of consumers and small businesses and their customers worldwide. Intuit is expanding its social, mobile, and global footprint with a full suite of products and services that are revolutionizing the industry. Utilizing design for delight and lean startup methodologies, our entrepreneurial employees have brought more than 250 innovations to market -- from QuickBooks®, Quicken®, and TurboTax®, to GoPayment, Mint.com, big data, cloud (SaaS, PaaS) and mobile apps. The breadth and depth of these customer-driven innovations mean limitless opportunities for you to turn your ingenious ideas into reality at Intuit.Discover what it’s like to be part of a team that rewards taking risks and trying new things. It’s time to love what you do! Check out all of our career opportunities at: http://jobs.intuit.com . EOE AA M/F/Vet/Disability\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-3+ years’; Engineering Mathematics; Theoretical/Computational\n",
      "Physics; small businesses; related field; business decisions; years’\n",
      "experience; Proven experience\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Description',\n",
       " 'Intuit',\n",
       " 'QuickBooks',\n",
       " 'is',\n",
       " 'on',\n",
       " 'a',\n",
       " 'mission',\n",
       " 'to',\n",
       " 'transform',\n",
       " 'small',\n",
       " 'business',\n",
       " 'lending',\n",
       " 'through',\n",
       " 'its',\n",
       " 'QuickBooks',\n",
       " 'Financing',\n",
       " 'Platform',\n",
       " '.',\n",
       " 'Powerful',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'a',\n",
       " 'sophisticated',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'our',\n",
       " 'customers',\n",
       " 'is',\n",
       " 'at',\n",
       " 'the',\n",
       " 'heart',\n",
       " 'of',\n",
       " 'our',\n",
       " 'business',\n",
       " '.',\n",
       " 'We',\n",
       " 'are',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'talented',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'to',\n",
       " 'join',\n",
       " 'our',\n",
       " 'team',\n",
       " 'and',\n",
       " 'help',\n",
       " 'build',\n",
       " 'financing',\n",
       " 'solutions',\n",
       " 'that',\n",
       " 'delight',\n",
       " 'our',\n",
       " 'SMB',\n",
       " 'customers',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'are',\n",
       " 'excited',\n",
       " 'about',\n",
       " 'joining',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'ambitious',\n",
       " 'and',\n",
       " 'talented',\n",
       " 'startup',\n",
       " 'team',\n",
       " ',',\n",
       " 'then',\n",
       " 'keep',\n",
       " 'reading',\n",
       " '!',\n",
       " 'Responsibilities',\n",
       " ':',\n",
       " 'Possess',\n",
       " 'a',\n",
       " 'wide-latitude',\n",
       " 'in',\n",
       " 'determining',\n",
       " 'objectives',\n",
       " 'and',\n",
       " 'approaches',\n",
       " 'to',\n",
       " 'solution',\n",
       " 'development',\n",
       " 'on',\n",
       " 'mission',\n",
       " 'critical',\n",
       " 'assignments',\n",
       " 'Go',\n",
       " 'beyond',\n",
       " 'established',\n",
       " 'analytical',\n",
       " 'thinking',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " 'by',\n",
       " 'applying',\n",
       " 'creativity',\n",
       " 'to',\n",
       " 'unconventional',\n",
       " 'concepts',\n",
       " 'and',\n",
       " 'out-of-the-box',\n",
       " 'solutions',\n",
       " 'Quickly',\n",
       " 'understand',\n",
       " 'patterns',\n",
       " 'within',\n",
       " 'large',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'data',\n",
       " 'and',\n",
       " 'to',\n",
       " 'reference',\n",
       " 'key',\n",
       " 'characteristics',\n",
       " 'using',\n",
       " 'visualization',\n",
       " 'techniques',\n",
       " 'Collaborate',\n",
       " 'with',\n",
       " 'infrastructure',\n",
       " 'architects',\n",
       " 'in',\n",
       " 'assessing',\n",
       " 'and',\n",
       " 'addressing',\n",
       " 'the',\n",
       " 'requirements',\n",
       " 'for',\n",
       " 'more',\n",
       " 'automated',\n",
       " ',',\n",
       " 'streamlined',\n",
       " 'systems',\n",
       " 'and',\n",
       " 'for',\n",
       " 'the',\n",
       " 'data',\n",
       " 'governance',\n",
       " 'required',\n",
       " 'for',\n",
       " 'agile',\n",
       " 'and',\n",
       " 'responsive',\n",
       " 'data',\n",
       " 'manipulation',\n",
       " 'Build',\n",
       " 'and',\n",
       " 'refine',\n",
       " 'a',\n",
       " 'predictive',\n",
       " 'model',\n",
       " 'around',\n",
       " 'when',\n",
       " 'small',\n",
       " 'businesses',\n",
       " 'are',\n",
       " 'most',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'need',\n",
       " 'financing',\n",
       " 'Inform',\n",
       " 'business',\n",
       " 'decisions',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'comprehensive',\n",
       " 'view',\n",
       " 'of',\n",
       " 'our',\n",
       " 'customers',\n",
       " 'by',\n",
       " 'combining',\n",
       " 'relevant',\n",
       " 'data',\n",
       " 'and',\n",
       " 'signals',\n",
       " 'from',\n",
       " 'multiple',\n",
       " 'sources',\n",
       " 'Make',\n",
       " 'recommendations',\n",
       " 'to',\n",
       " 'enhance',\n",
       " 'marketing',\n",
       " 'strategy',\n",
       " 'by',\n",
       " 'deeply',\n",
       " 'understanding',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'every',\n",
       " 'channel',\n",
       " 'Partner',\n",
       " 'directly',\n",
       " 'with',\n",
       " 'the',\n",
       " 'product',\n",
       " 'development',\n",
       " 'team',\n",
       " 'on',\n",
       " 'product',\n",
       " 'instrumentation',\n",
       " ',',\n",
       " 'product',\n",
       " 'flow',\n",
       " 'and',\n",
       " 'data',\n",
       " 'capture',\n",
       " 'Inform',\n",
       " 'product',\n",
       " 'strategy',\n",
       " 'by',\n",
       " 'designing',\n",
       " 'A/B',\n",
       " 'tests',\n",
       " 'and',\n",
       " 'analyzing',\n",
       " 'customer',\n",
       " 'behavior',\n",
       " 'on',\n",
       " 'our',\n",
       " 'platform',\n",
       " 'Build',\n",
       " 'dashboards',\n",
       " 'to',\n",
       " 'support',\n",
       " 'day',\n",
       " 'to',\n",
       " 'day',\n",
       " 'business',\n",
       " 'decisions',\n",
       " 'Work',\n",
       " 'closely',\n",
       " 'with',\n",
       " 'product',\n",
       " ',',\n",
       " 'marketing',\n",
       " ',',\n",
       " 'legal',\n",
       " ',',\n",
       " 'compliance',\n",
       " ',',\n",
       " 'capital',\n",
       " 'markets',\n",
       " 'and',\n",
       " 'our',\n",
       " 'current',\n",
       " 'lending',\n",
       " 'partners',\n",
       " 'Qualifications',\n",
       " 'Proven',\n",
       " 'leadership',\n",
       " 'experience',\n",
       " 'in',\n",
       " 'the',\n",
       " 'domain',\n",
       " 'of',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'MS',\n",
       " 'in',\n",
       " 'Engineering',\n",
       " 'Mathematics',\n",
       " ',',\n",
       " 'Statistics',\n",
       " ',',\n",
       " 'Theoretical/Computational',\n",
       " 'Physics',\n",
       " ',',\n",
       " 'or',\n",
       " 'related',\n",
       " 'field',\n",
       " 'Solid',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'techniques',\n",
       " 'is',\n",
       " 'required',\n",
       " 'Hands-on',\n",
       " 'programming',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'one',\n",
       " 'or',\n",
       " 'more',\n",
       " 'of',\n",
       " 'the',\n",
       " 'following',\n",
       " ':',\n",
       " 'Java',\n",
       " ',',\n",
       " 'Python',\n",
       " ',',\n",
       " 'R',\n",
       " ',',\n",
       " 'or',\n",
       " 'related',\n",
       " 'languages',\n",
       " '1-3+',\n",
       " 'years’',\n",
       " 'experience',\n",
       " 'manipulating',\n",
       " 'large',\n",
       " 'datasets',\n",
       " 'and',\n",
       " 'using',\n",
       " 'databases',\n",
       " '(',\n",
       " 'e.g',\n",
       " '.',\n",
       " 'SAS',\n",
       " ',',\n",
       " 'R',\n",
       " ',',\n",
       " 'SQL',\n",
       " ',',\n",
       " 'S-Plus',\n",
       " ',',\n",
       " 'etc',\n",
       " '.',\n",
       " ')',\n",
       " '1-3+',\n",
       " 'years’',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'a',\n",
       " 'general-purpose',\n",
       " 'programming',\n",
       " 'language',\n",
       " '(',\n",
       " 'e.g',\n",
       " '.',\n",
       " 'C',\n",
       " ',',\n",
       " 'Java',\n",
       " ',',\n",
       " 'Python',\n",
       " ',',\n",
       " 'etc',\n",
       " '.',\n",
       " ')',\n",
       " 'Familiarity',\n",
       " 'with',\n",
       " 'basic',\n",
       " 'principles',\n",
       " 'of',\n",
       " 'distributed',\n",
       " 'computing',\n",
       " 'and/or',\n",
       " 'distributed',\n",
       " 'databases',\n",
       " '(',\n",
       " 'Hadoop',\n",
       " ',',\n",
       " 'NoSQL',\n",
       " ',',\n",
       " 'etc',\n",
       " '.',\n",
       " ')',\n",
       " 'Demonstrable',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'quickly',\n",
       " 'understand',\n",
       " 'new',\n",
       " 'concepts',\n",
       " '--',\n",
       " '-all',\n",
       " 'the',\n",
       " 'way',\n",
       " 'down',\n",
       " 'to',\n",
       " 'the',\n",
       " 'theorems—and',\n",
       " 'to',\n",
       " 'come',\n",
       " 'out',\n",
       " 'with',\n",
       " 'original',\n",
       " 'solutions',\n",
       " 'to',\n",
       " 'mathematical',\n",
       " 'issues',\n",
       " 'Strong',\n",
       " 'interpersonal',\n",
       " 'and',\n",
       " 'communication',\n",
       " 'skills',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'effectively',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'technical',\n",
       " 'teams',\n",
       " 'and',\n",
       " 'make',\n",
       " 'presentations',\n",
       " 'to',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'technical',\n",
       " 'and',\n",
       " 'business',\n",
       " 'personnel',\n",
       " 'Demonstrable',\n",
       " 'skills',\n",
       " 'in',\n",
       " 'creative-problem-solving',\n",
       " 'of',\n",
       " 'complex',\n",
       " 'and',\n",
       " 'advanced',\n",
       " 'technical',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'Strongly',\n",
       " 'Preferred',\n",
       " ':',\n",
       " 'PhD',\n",
       " 'in',\n",
       " 'Engineering',\n",
       " 'Mathematics',\n",
       " ',',\n",
       " 'Statistics',\n",
       " ',',\n",
       " 'Theoretical/Computational',\n",
       " 'Physics',\n",
       " ',',\n",
       " 'or',\n",
       " 'related',\n",
       " 'field',\n",
       " 'Proven',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'techniques',\n",
       " ',',\n",
       " 'especially',\n",
       " 'on',\n",
       " 'large',\n",
       " 'scale',\n",
       " 'datasets',\n",
       " 'Proven',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'Hadoop',\n",
       " 'and',\n",
       " 'related',\n",
       " 'programming',\n",
       " 'environments',\n",
       " '(',\n",
       " 'Hive',\n",
       " ',',\n",
       " 'Pig',\n",
       " ',',\n",
       " 'etc',\n",
       " ')',\n",
       " 'Imagine',\n",
       " 'a',\n",
       " 'career',\n",
       " 'where',\n",
       " 'your',\n",
       " 'creative',\n",
       " 'inspiration',\n",
       " 'can',\n",
       " 'fuel',\n",
       " 'BIG',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Year-over-year',\n",
       " ',',\n",
       " 'Intuit',\n",
       " 'has',\n",
       " 'been',\n",
       " 'recognized',\n",
       " 'as',\n",
       " 'a',\n",
       " 'best',\n",
       " 'employer',\n",
       " 'and',\n",
       " 'is',\n",
       " 'consistently',\n",
       " 'ranked',\n",
       " 'on',\n",
       " 'Fortune',\n",
       " \"'s\",\n",
       " '“100',\n",
       " 'Best',\n",
       " 'Companies',\n",
       " 'To',\n",
       " 'Work',\n",
       " 'For”',\n",
       " 'and',\n",
       " 'Fortune',\n",
       " 'World’s',\n",
       " '“Most',\n",
       " 'Admired',\n",
       " 'Software',\n",
       " 'Companies”',\n",
       " 'lists',\n",
       " '.',\n",
       " 'Immerse',\n",
       " 'yourself',\n",
       " 'in',\n",
       " 'our',\n",
       " 'award',\n",
       " 'winning',\n",
       " 'culture',\n",
       " 'while',\n",
       " 'creating',\n",
       " 'breakthrough',\n",
       " 'solutions',\n",
       " 'that',\n",
       " 'simplify',\n",
       " 'the',\n",
       " 'lives',\n",
       " 'of',\n",
       " 'consumers',\n",
       " 'and',\n",
       " 'small',\n",
       " 'businesses',\n",
       " 'and',\n",
       " 'their',\n",
       " 'customers',\n",
       " 'worldwide',\n",
       " '.',\n",
       " 'Intuit',\n",
       " 'is',\n",
       " 'expanding',\n",
       " 'its',\n",
       " 'social',\n",
       " ',',\n",
       " 'mobile',\n",
       " ',',\n",
       " 'and',\n",
       " 'global',\n",
       " 'footprint',\n",
       " 'with',\n",
       " 'a',\n",
       " 'full',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'products',\n",
       " 'and',\n",
       " 'services',\n",
       " 'that',\n",
       " 'are',\n",
       " 'revolutionizing',\n",
       " 'the',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Utilizing',\n",
       " 'design',\n",
       " 'for',\n",
       " 'delight',\n",
       " 'and',\n",
       " 'lean',\n",
       " 'startup',\n",
       " 'methodologies',\n",
       " ',',\n",
       " 'our',\n",
       " 'entrepreneurial',\n",
       " 'employees',\n",
       " 'have',\n",
       " 'brought',\n",
       " 'more',\n",
       " 'than',\n",
       " '250',\n",
       " 'innovations',\n",
       " 'to',\n",
       " 'market',\n",
       " '--',\n",
       " 'from',\n",
       " 'QuickBooks®',\n",
       " ',',\n",
       " 'Quicken®',\n",
       " ',',\n",
       " 'and',\n",
       " 'TurboTax®',\n",
       " ',',\n",
       " 'to',\n",
       " 'GoPayment',\n",
       " ',',\n",
       " 'Mint.com',\n",
       " ',',\n",
       " 'big',\n",
       " 'data',\n",
       " ',',\n",
       " 'cloud',\n",
       " '(',\n",
       " 'SaaS',\n",
       " ',',\n",
       " 'PaaS',\n",
       " ')',\n",
       " 'and',\n",
       " 'mobile',\n",
       " 'apps',\n",
       " '.',\n",
       " 'The',\n",
       " 'breadth',\n",
       " 'and',\n",
       " 'depth',\n",
       " 'of',\n",
       " 'these',\n",
       " 'customer-driven',\n",
       " 'innovations',\n",
       " 'mean',\n",
       " 'limitless',\n",
       " 'opportunities',\n",
       " 'for',\n",
       " 'you',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'your',\n",
       " 'ingenious',\n",
       " 'ideas',\n",
       " 'into',\n",
       " 'reality',\n",
       " 'at',\n",
       " 'Intuit.Discover',\n",
       " 'what',\n",
       " 'it’s',\n",
       " 'like',\n",
       " 'to',\n",
       " 'be',\n",
       " 'part',\n",
       " 'of',\n",
       " 'a',\n",
       " 'team',\n",
       " 'that',\n",
       " 'rewards',\n",
       " 'taking',\n",
       " 'risks',\n",
       " 'and',\n",
       " 'trying',\n",
       " 'new',\n",
       " 'things',\n",
       " '.',\n",
       " 'It’s',\n",
       " 'time',\n",
       " 'to',\n",
       " 'love',\n",
       " 'what',\n",
       " 'you',\n",
       " 'do',\n",
       " '!',\n",
       " 'Check',\n",
       " 'out',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'career',\n",
       " 'opportunities',\n",
       " 'at',\n",
       " ':',\n",
       " 'http',\n",
       " ':',\n",
       " '//jobs.intuit.com',\n",
       " '.',\n",
       " 'EOE',\n",
       " 'AA',\n",
       " 'M/F/Vet/Disability']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-08e2b39636ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Hive'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "k = 'Hive'\n",
    "[w for w in text if k in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'crab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f8dbd0661885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcrab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'crab'"
     ]
    }
   ],
   "source": [
    "import crab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'crab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f8dbd0661885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcrab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'crab'"
     ]
    }
   ],
   "source": [
    "import crab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
